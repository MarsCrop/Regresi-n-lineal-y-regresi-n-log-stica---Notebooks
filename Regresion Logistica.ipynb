{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Ideas\n",
    "\n",
    "### Aprendizaje supervisado\n",
    "\n",
    "¿Qué es el aprendizaje supervisado? Consiste en obtener variables categóricas a partir de datos presentados en un contexto donde el objetivo es obtener una función de decisión, la cual sirve como límite para establecer las acciones correspondientes a tomar con una muestra específica de acuerdo a su **clase** correspondiente, siendo la **clase** la variable categórica que se quiere extraer o deducir a partir de su **variable de decisión**. \n",
    "Una forma de aplicar estos conceptos en un contexto de análisis para realizar una tarea de reconocimiento puede ser durante el reconocimiento de perros y gatos: las clases serán 'perro' y 'gato' y nuestras variables de decisión deberán respaldar nuestra hipótesis de que la forma de la nariz es la que nos permite distinguir fotográficamente entre un perro y un gato. Las variables de decisión deberán establecer un ajuste óptimo para separar perros y gatos de acuerdo a la forma de la nariz.\n",
    "Cabe aclarar que en el aprendizaje supervisado la decisión esta influenciada por variables categóricas que también se ajustan a la decisión tomada, es decir que tenemos que entrenar un vector de categorías junto con nuestro vector de datos x que consistirá en los datos que utilizamos anteriormente para calcular la tendencia entre los datos.\n",
    "\n",
    "### Supervisación y regiones factibles\n",
    "\n",
    "Antes de adentrarnos sobre medidas conocidas para analizar resultados de problemas supervisados hace falta adentrarse un poco mas en lo que se conoce como **programación lineal. La programación lineal es un paradigma de programación que consiste en resolver inecuaciones (estos son problemas cuyas soluciones requieren de satisfacción de restricciones matemáticas para poder resolverse debido a que los problemas no se resolverán aplicando ecuaciones sobre el conjunto total de variables en un plano) para obtener regiones de viabilidad o regiones de factibilidad que establecen qué conjunto de variables resuelven una ecuación de forma válida.**\n",
    "Las regiones factibles surgen del hallazgo de polihedros y márgenes de separación en una nube de puntos que se obtienen mediante la resolución de inecuaciones.\n",
    "**No todos los problemas de programación lineal se pueden resolver en un tiempo razonable para nosotros, por lo que ese tipo de problemas permanecen en nuestra incógnita. Por suerte, varios problemas de aprendizaje supervisado contienen muy buenos algoritmos que nos permiten encontrar diversas soluciones para varios conjuntos de datos en un tiempo bastante corto.**\n",
    "\n",
    "### Decisión y confusión\n",
    "\n",
    "De las teorías de programación lineal surge un concepto necesario a aplicar en problemas de aprendizaje supervisado: el de los **límites de decisión**. Los límites de decisión se deducen a partir de la resolución del problema de regresión subyacente en un contexto de aprendizaje supervisado. Dichos límites estan ubicados en aquellos puntos en el plano donde la clasificación resulta ambigua y la resolución de la ecuación de regresión en esos puntos nos da un resultado que anula la posibilidad de obtener clases en esas partes, por lo que resultan ser límites entre una clase y la otra.\n",
    "Esto acarrea un problema que se debe medir con cautela a la hora de encarar un proyecto de Machine Learning. Para medir el éxito operativo **hay varios métodos y varias fórmulas que buscan ajustar modelos de entrenamiento y de prueba a un punto donde las condiciones de análisis son óptimas**. En este curso nosotros vamos a ver las medidas de una **matriz de confusión**.\n",
    "\n",
    "##### ¿Qué es una matriz de confusión?\n",
    "\n",
    "    * Es una matriz que contiene información estadística acerca del acierto en la clasificación.\n",
    "    * Los datos alojados en la matriz de confusión contienen en la diagonal la cantidad de variables original, mientras que las variables predecidas se leen a partir de las columnas de la matriz de confusión.\n",
    "    * Se llama matriz de confusión porque nos permite obtener resultados sobre el éxito de nuestro modelo a partir del conocimiento sobre las muestras mal clasificadas.\n",
    "    * Para ver una matriz de confusión solamente utilizamos como argumentos para el método confusion_matrix de scikit-learn los valores originales de y con los valores predecidos de y.\n",
    "    * Luego visualizamos la matriz de confusión programando una función que permita intensificar con un color oscuro aquellos valores que aparecen predecidos demasiadas veces, esto nos da una mejor idea de cuál es la categoría a la que el modelo esta haciendo énfasis cuando el error es alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAboAAAEmCAYAAAAUU1W9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8689233f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nombres de nuestras variables categoricas\n",
    "\n",
    "generos = ['Rock',\n",
    " 'Pop',\n",
    " 'Metal',\n",
    " 'Country',\n",
    " 'Rap',\n",
    " 'RnB*',\n",
    " 'Electronic',\n",
    " 'Punk',\n",
    " 'Latin',\n",
    " 'Folk',\n",
    " 'Reggae',\n",
    " 'Jazz',\n",
    " 'Blues',\n",
    " 'World',\n",
    " 'New',\n",
    " 'Native']\n",
    "\n",
    "# variables categóricas expresadas en números\n",
    "y = [14,  1,  9, 15, 10, 15,  6, 14,  3,  1, 14,  5,  5,  3, 13, 10,  3,\n",
    "        1,  3,  0, 10,  7, 12, 12,  5, 14,  2,  7, 12, 10,  4,  3,  9, 14,\n",
    "       14,  5,  1, 14,  7, 14, 12, 14,  0, 12,  8,  7,  0, 14, 11, 11, 11,\n",
    "       11, 11, 11, 11, 11, 11, 11, 11, 11, 13, 11,  6, 11, 12, 13,  1, 11,\n",
    "       11,  6, 11,  0, 11, 10, 11, 11, 11, 11, 15,  9,  9, 11, 11, 11, 11,\n",
    "        5, 15, 11,  0,  7, 14,  5,  7, 10, 12, 12, 13,  3, 10, 10,  7,  9,\n",
    "        5, 10,  4, 13,  7,  5,  1,  6,  0,  8, 10,  6, 11, 11, 11, 10,  5,\n",
    "        3, 12,  6,  1,  3,  6, 10,  3, 12,  1, 15, 11, 11]\n",
    "\n",
    "#variables predecidas por un algoritmo de aprendizaje supervisado\n",
    "p = [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
    "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
    "        2,  2,  2,  2, 10,  2,  2,  2,  2,  2, 11,  2, 11,  2,  4,  4,  4,\n",
    "        4, 11,  8,  4,  8,  8,  4,  4,  4,  2,  4,  2,  4,  2,  2,  2,  4,\n",
    "        4,  2,  4, 11,  4,  2, 11,  4,  4,  4,  2,  2,  2, 11,  4,  4,  4,\n",
    "        2,  2,  4,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
    "        2,  2,  2,  2,  2,  2,  2,  2,  2, 11,  2,  2, 11, 11,  4,  2,  2,\n",
    "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2, 11,  4,  4]\n",
    "\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Matriz de confusión - Clasificación de canciones por géneros musicales',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('y original')\n",
    "    plt.xlabel('y predecida')    \n",
    "    plt.show()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf = confusion_matrix(y, p)\n",
    "plot_confusion_matrix(cf,generos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La matriz de confusión nos permite hacer lo que se conoce como contraste de hipótesis; esto es, verificar si podemos efectivamente utilizar las variables predecidas de y o aún debemos entrenar el modelo con mejor información para superar los resultados de y original**.\n",
    "Para realizar nuestro contraste de hipótesis tendremos que calcular información que se puede obtener de la matriz de confusión. Esta información esta compuesta por:\n",
    "    * Los falsos positivos\n",
    "    * Los falsos negativos\n",
    "    * Los verdaderos positivos\n",
    "    * Los verdaderos negativos\n",
    "    * El porcentaje de acierto \n",
    "    * La reminiscencia\n",
    "    * La especificidad\n",
    "    * La precisión\n",
    "    * La media harmónica\n",
    "    \n",
    "#### ¿Qué son los falsos positivos?\n",
    "    \n",
    "    Los falsos positivos (también llamados errores de tipo I o errores de tipo alfa) son muestras cuyas variables categóricas positivas predecidas son falsas, es decir que se le asignan variables categóricas positivas a muestras que deberían tener variables categóricas negativas. Para obtener los falsos positivos simplemente hay que obtener el total de variables por cada fila y substraer las variables de y originales (las cuales se encuentran obteniendo la diagonal de la matriz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falsos positivos en el reconocimiento de canciones de  Rock  es  0\n",
      "Falsos positivos en el reconocimiento de canciones de  Pop  es  0\n",
      "Falsos positivos en el reconocimiento de canciones de  Metal  es  93\n",
      "Falsos positivos en el reconocimiento de canciones de  Country  es  0\n",
      "Falsos positivos en el reconocimiento de canciones de  Rap  es  24\n",
      "Falsos positivos en el reconocimiento de canciones de  RnB*  es  0\n",
      "Falsos positivos en el reconocimiento de canciones de  Electronic  es  0\n",
      "Falsos positivos en el reconocimiento de canciones de  Punk  es  0\n",
      "Falsos positivos en el reconocimiento de canciones de  Latin  es  3\n",
      "Falsos positivos en el reconocimiento de canciones de  Folk  es  0\n",
      "Falsos positivos en el reconocimiento de canciones de  Reggae  es  1\n",
      "Falsos positivos en el reconocimiento de canciones de  Jazz  es  5\n",
      "Falsos positivos en el reconocimiento de canciones de  Blues  es  0\n",
      "Falsos positivos en el reconocimiento de canciones de  World  es  0\n",
      "Falsos positivos en el reconocimiento de canciones de  New  es  0\n",
      "Falsos positivos en el reconocimiento de canciones de  Native  es  0\n"
     ]
    }
   ],
   "source": [
    "TP = np.diag(cf)\n",
    "\n",
    "FP = cf.sum(axis=0) - TP\n",
    "\n",
    "for i in range(len(generos)):\n",
    "    print(\"Falsos positivos en el reconocimiento de canciones de \", generos[i], ' es ', FP[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Qué son los falsos negativos?\n",
    "    \n",
    "    Los falsos positivos (también llamados errores de tipo II o errores de tipo beta) son muestras cuya variables categóricas negativas predecidas son falsas, es decir que se le asignan variables categóricas negativas a muestras que no lo son. Para obtener los falsos negativos simplemente hay que obtener el total de variables por cada columna y substraer las variables de y originales (las cuales se encuentran obteniendo la diagonal de la matriz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falsos negativos en el reconocimiento de canciones de  Rock  es  6\n",
      "Falsos negativos en el reconocimiento de canciones de  Pop  es  8\n",
      "Falsos negativos en el reconocimiento de canciones de  Metal  es  0\n",
      "Falsos negativos en el reconocimiento de canciones de  Country  es  9\n",
      "Falsos negativos en el reconocimiento de canciones de  Rap  es  2\n",
      "Falsos negativos en el reconocimiento de canciones de  RnB*  es  9\n",
      "Falsos negativos en el reconocimiento de canciones de  Electronic  es  7\n",
      "Falsos negativos en el reconocimiento de canciones de  Punk  es  8\n",
      "Falsos negativos en el reconocimiento de canciones de  Latin  es  2\n",
      "Falsos negativos en el reconocimiento de canciones de  Folk  es  5\n",
      "Falsos negativos en el reconocimiento de canciones de  Reggae  es  12\n",
      "Falsos negativos en el reconocimiento de canciones de  Jazz  es  27\n",
      "Falsos negativos en el reconocimiento de canciones de  Blues  es  10\n",
      "Falsos negativos en el reconocimiento de canciones de  World  es  5\n",
      "Falsos negativos en el reconocimiento de canciones de  New  es  11\n",
      "Falsos negativos en el reconocimiento de canciones de  Native  es  5\n"
     ]
    }
   ],
   "source": [
    "FN = cf.sum(axis=1) - TP\n",
    "\n",
    "for i in range(len(generos)):\n",
    "    print(\"Falsos negativos en el reconocimiento de canciones de \", generos[i], ' es ', FN[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Qué son los verdaderos positivos?\n",
    "    \n",
    "    Los verdaderos positivos son muestras cuya categoría predecida se corresponde con la categoría original. Para obtener los verdaderos positivos dada una matriz de confusión simplemente hay que prestar atención a la diagonal de la matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdaderos positivos en el reconocimiento de canciones de  Rock  es  0\n",
      "Verdaderos positivos en el reconocimiento de canciones de  Pop  es  0\n",
      "Verdaderos positivos en el reconocimiento de canciones de  Metal  es  1\n",
      "Verdaderos positivos en el reconocimiento de canciones de  Country  es  0\n",
      "Verdaderos positivos en el reconocimiento de canciones de  Rap  es  0\n",
      "Verdaderos positivos en el reconocimiento de canciones de  RnB*  es  0\n",
      "Verdaderos positivos en el reconocimiento de canciones de  Electronic  es  0\n",
      "Verdaderos positivos en el reconocimiento de canciones de  Punk  es  0\n",
      "Verdaderos positivos en el reconocimiento de canciones de  Latin  es  0\n",
      "Verdaderos positivos en el reconocimiento de canciones de  Folk  es  0\n",
      "Verdaderos positivos en el reconocimiento de canciones de  Reggae  es  0\n",
      "Verdaderos positivos en el reconocimiento de canciones de  Jazz  es  5\n",
      "Verdaderos positivos en el reconocimiento de canciones de  Blues  es  0\n",
      "Verdaderos positivos en el reconocimiento de canciones de  World  es  0\n",
      "Verdaderos positivos en el reconocimiento de canciones de  New  es  0\n",
      "Verdaderos positivos en el reconocimiento de canciones de  Native  es  0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(generos)):\n",
    "    print(\"Verdaderos positivos en el reconocimiento de canciones de \", generos[i], ' es ', TP[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Qué son los verdaderos negativos?\n",
    "    \n",
    "    Los verdaderos negativos son muestras cuya categoría predecida se corresponde con la categoría original y  la categoría es negativa. Para obtener los verdaderos negativos dada una matriz de confusión hay que sumar, por un lado, todas las variables en la matriz de confusión, y luego se debe sustraer a ese total el resultado de la suma de los falsos negativos, falsos positivos y verdaderos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdaderos negativos en el reconocimiento de canciones de  Rock  es  126\n",
      "Verdaderos negativos en el reconocimiento de canciones de  Pop  es  124\n",
      "Verdaderos negativos en el reconocimiento de canciones de  Metal  es  38\n",
      "Verdaderos negativos en el reconocimiento de canciones de  Country  es  123\n",
      "Verdaderos negativos en el reconocimiento de canciones de  Rap  es  106\n",
      "Verdaderos negativos en el reconocimiento de canciones de  RnB*  es  123\n",
      "Verdaderos negativos en el reconocimiento de canciones de  Electronic  es  125\n",
      "Verdaderos negativos en el reconocimiento de canciones de  Punk  es  124\n",
      "Verdaderos negativos en el reconocimiento de canciones de  Latin  es  127\n",
      "Verdaderos negativos en el reconocimiento de canciones de  Folk  es  127\n",
      "Verdaderos negativos en el reconocimiento de canciones de  Reggae  es  119\n",
      "Verdaderos negativos en el reconocimiento de canciones de  Jazz  es  95\n",
      "Verdaderos negativos en el reconocimiento de canciones de  Blues  es  122\n",
      "Verdaderos negativos en el reconocimiento de canciones de  World  es  127\n",
      "Verdaderos negativos en el reconocimiento de canciones de  New  es  121\n",
      "Verdaderos negativos en el reconocimiento de canciones de  Native  es  127\n"
     ]
    }
   ],
   "source": [
    "TN = cf.sum() - (FP + FN + TP) #verdadero negativo\n",
    "\n",
    "for i in range(len(generos)):\n",
    "    print(\"Verdaderos negativos en el reconocimiento de canciones de \", generos[i], ' es ', TN[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Qué es el acierto o accuracy score?\n",
    "    \n",
    "    El porcentaje de acierto o accuracy score es un porcentaje que nos permite interpretar el error sistemático, también llamado sesgo estadístico durante el entrenamiento de los datos para poder categorizar todas las muestras. El acierto simplemente estará conformando por la relación entre las variables predecidas correctamente y la sumatoria de estas variables junto con las que no fueron predecidas correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto en el reconocimiento de canciones de  Rock  es  95.4545454545\n",
      "Acierto en el reconocimiento de canciones de  Pop  es  93.9393939394\n",
      "Acierto en el reconocimiento de canciones de  Metal  es  29.5454545455\n",
      "Acierto en el reconocimiento de canciones de  Country  es  93.1818181818\n",
      "Acierto en el reconocimiento de canciones de  Rap  es  80.303030303\n",
      "Acierto en el reconocimiento de canciones de  RnB*  es  93.1818181818\n",
      "Acierto en el reconocimiento de canciones de  Electronic  es  94.696969697\n",
      "Acierto en el reconocimiento de canciones de  Punk  es  93.9393939394\n",
      "Acierto en el reconocimiento de canciones de  Latin  es  96.2121212121\n",
      "Acierto en el reconocimiento de canciones de  Folk  es  96.2121212121\n",
      "Acierto en el reconocimiento de canciones de  Reggae  es  90.1515151515\n",
      "Acierto en el reconocimiento de canciones de  Jazz  es  75.7575757576\n",
      "Acierto en el reconocimiento de canciones de  Blues  es  92.4242424242\n",
      "Acierto en el reconocimiento de canciones de  World  es  96.2121212121\n",
      "Acierto en el reconocimiento de canciones de  New  es  91.6666666667\n",
      "Acierto en el reconocimiento de canciones de  Native  es  96.2121212121\n"
     ]
    }
   ],
   "source": [
    "acierto = (TP+TN)/(TP+FP+FN+TN) * 100\n",
    "\n",
    "for i in range(len(generos)):\n",
    "    print(\"Acierto en el reconocimiento de canciones de \", generos[i], ' es ', acierto[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, el acierto en el reconocimiento parece ser bueno, por lo que hemos elegido buenas columnas de rasgos para poder reconocer los géneros musicales.\n",
    "El único (y fuerte) sesgo que aparece es el de no identificar correctamente canciones de heavy metal. Si leemos un poco la información obtenida sobre los datos correctamente clasificados, veremos que varias canciones fueron identificadas como heavy metal cuando en realidad no lo son, lo cual es indicio de que es necesario contar con información recogida sobre mayores cantidades de canciones de heavy metal para eliminar el sesgo y obtener un porcentaje de acierto mayor en el reconocimiento de canciones de heavy metal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensibilidad/reminiscencia y especificidad\n",
    "    \n",
    "    Tanto la sensibilidad como la especificidad son las medidas que debemos utilizar cuando queremos medir la performance de nuestro modelo.\n",
    "    La sensibilidad es el porcentaje de positivos correctamente identificados por nuestro modelo (esto es, el tamaño de verdaderos positivos sobre la suma de estos con el tamaño de falsos negativos). La sensibilidad (también llamada reminiscencia) junto con la medida de error que escogemos para validar nuestro análisis son dos medidas cruciales para decir que nuestro modelo entrena bien los datos.\n",
    "    La especificidad es el porcentaje de negativos correctamente identificados por nuestro modelo (esto es, el tamaño de verdaderos negativos sobre la suma de estos con el tamaño de falsos positivos).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad en el reconocimiento de canciones de  Rock :  0.0\n",
      "Sensibilidad en el reconocimiento de canciones de  Pop :  0.0\n",
      "Sensibilidad en el reconocimiento de canciones de  Metal :  100.0\n",
      "Sensibilidad en el reconocimiento de canciones de  Country :  0.0\n",
      "Sensibilidad en el reconocimiento de canciones de  Rap :  0.0\n",
      "Sensibilidad en el reconocimiento de canciones de  RnB* :  0.0\n",
      "Sensibilidad en el reconocimiento de canciones de  Electronic :  0.0\n",
      "Sensibilidad en el reconocimiento de canciones de  Punk :  0.0\n",
      "Sensibilidad en el reconocimiento de canciones de  Latin :  0.0\n",
      "Sensibilidad en el reconocimiento de canciones de  Folk :  0.0\n",
      "Sensibilidad en el reconocimiento de canciones de  Reggae :  0.0\n",
      "Sensibilidad en el reconocimiento de canciones de  Jazz :  15.625\n",
      "Sensibilidad en el reconocimiento de canciones de  Blues :  0.0\n",
      "Sensibilidad en el reconocimiento de canciones de  World :  0.0\n",
      "Sensibilidad en el reconocimiento de canciones de  New :  0.0\n",
      "Sensibilidad en el reconocimiento de canciones de  Native :  0.0\n",
      "Especificidad en el reconocimiento de canciones de  Rock :  100.0\n",
      "Especificidad en el reconocimiento de canciones de  Pop :  100.0\n",
      "Especificidad en el reconocimiento de canciones de  Metal :  29.0076335878\n",
      "Especificidad en el reconocimiento de canciones de  Country :  100.0\n",
      "Especificidad en el reconocimiento de canciones de  Rap :  81.5384615385\n",
      "Especificidad en el reconocimiento de canciones de  RnB* :  100.0\n",
      "Especificidad en el reconocimiento de canciones de  Electronic :  100.0\n",
      "Especificidad en el reconocimiento de canciones de  Punk :  100.0\n",
      "Especificidad en el reconocimiento de canciones de  Latin :  97.6923076923\n",
      "Especificidad en el reconocimiento de canciones de  Folk :  100.0\n",
      "Especificidad en el reconocimiento de canciones de  Reggae :  99.1666666667\n",
      "Especificidad en el reconocimiento de canciones de  Jazz :  95.0\n",
      "Especificidad en el reconocimiento de canciones de  Blues :  100.0\n",
      "Especificidad en el reconocimiento de canciones de  World :  100.0\n",
      "Especificidad en el reconocimiento de canciones de  New :  100.0\n",
      "Especificidad en el reconocimiento de canciones de  Native :  100.0\n"
     ]
    }
   ],
   "source": [
    "# reminiscencia (tamaño de verdaderos positivos)\n",
    "sensibilidad = TP/(TP+FN) * 100\n",
    "# tamaño de verdaderos negativos\n",
    "especificidad = TN/(TN+FP) * 100\n",
    "\n",
    "for i in range(len(generos)):\n",
    "    print(\"Sensibilidad en el reconocimiento de canciones de \", generos[i], ': ', sensibilidad[i])\n",
    "    \n",
    "for i in range(len(generos)):\n",
    "    print(\"Especificidad en el reconocimiento de canciones de \", generos[i], ': ', especificidad[i])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La especificidad, como pueden ver, no nos brinda tanta información como si lo hace la sensibilidad. La sensibilidad para reconocer canciones de Jazz es muy pobre, mientras que la especificidad en el reconocimiento de canciones de heavy metal también lo es, por lo que nuestro modelo tiene sesgos enormes a la hora de reconocer canciones de heavy metal o de jazz.\n",
    "Utilizar las medidas de acierto junto con las medidas de reminiscencia nos dan una muy buena idea del sesgo estadístico y de la performance de nuestro modelo para reconocer canciones correctamente (saber cuanta información relevante pudimos recoger).\n",
    "\n",
    "### ¿Qué es la precisión?\n",
    "    \n",
    "    La precisión es parecida a la reminiscencia conceptualmente, pero hay una pequeña diferencia: la precisión consiste en el hallazgo de información relevante dentro del conjunto total de información recabada (de clases predecidas), mientras que la sensibilidad o reminiscencia consiste en el hallazgo de información relevante dentro del total de información relevante (son los elementos relevantes seleccionados positivamente los que caracterizan la sensibilidad).\n",
    "    Sin embargo, esta diferencia no hace menos útil a la precisión, ya que para calcularla debemos saber cuál es el valor predictivo positivo que hay en nuestro modelo. Sin tener una idea de cuál es el valor predictivo positivo no podemos tener una idea de qué tan sensible es nuestro modelo. Si la sensibilidad es alta, la precisión también tiene que serlo para saber que nuestro modelo puede reconocer categorías a partir de diversos objetos o muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision en el reconocimiento de canciones de  Rock :  nan\n",
      "Precision en el reconocimiento de canciones de  Pop :  nan\n",
      "Precision en el reconocimiento de canciones de  Metal :  1.06382978723\n",
      "Precision en el reconocimiento de canciones de  Country :  nan\n",
      "Precision en el reconocimiento de canciones de  Rap :  0.0\n",
      "Precision en el reconocimiento de canciones de  RnB* :  nan\n",
      "Precision en el reconocimiento de canciones de  Electronic :  nan\n",
      "Precision en el reconocimiento de canciones de  Punk :  nan\n",
      "Precision en el reconocimiento de canciones de  Latin :  0.0\n",
      "Precision en el reconocimiento de canciones de  Folk :  nan\n",
      "Precision en el reconocimiento de canciones de  Reggae :  0.0\n",
      "Precision en el reconocimiento de canciones de  Jazz :  50.0\n",
      "Precision en el reconocimiento de canciones de  Blues :  nan\n",
      "Precision en el reconocimiento de canciones de  World :  nan\n",
      "Precision en el reconocimiento de canciones de  New :  nan\n",
      "Precision en el reconocimiento de canciones de  Native :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# precision (valor predictivo positivo)\n",
    "precision = TP/(TP+FP) * 100\n",
    "\n",
    "for i in range(len(generos)):\n",
    "    print(\"Precision en el reconocimiento de canciones de \", generos[i], ': ', precision[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las medidas de precisión no contrastan con las medidas de sensibilidad: cuando el modelo no es sensible tampoco lo es la precisión. Del total de canciones consideradas como canciones de Jazz, solamente la mitad lo son verdaderamente, lo cual debe causar el sesgo a la hora de reconocer canciones de heavy metal. Vamos a medir un poco mas la performance de nuestro modelo con una última medida de interés para entender lo que estamos haciendo. \n",
    "\n",
    "### ¿ Qué es el puntaje F1?\n",
    "    \n",
    "    El porcentaje F1 es la media harmónica dadas la precisión y la sensibilidad, entendiendo a ambas medidas como recíprocos (esto es como múltiplos de una cantidad pequeña de información relevante) para asi obtener una medida promedio de la performance de todo el sistema y no ver la precisión y la sensibilidad como cuestiones apartadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance general en el reconocimiento de  Rock :  nan\n",
      "Performance general en el reconocimiento de  Pop :  nan\n",
      "Performance general en el reconocimiento de  Metal :  2.10526315789\n",
      "Performance general en el reconocimiento de  Country :  nan\n",
      "Performance general en el reconocimiento de  Rap :  nan\n",
      "Performance general en el reconocimiento de  RnB* :  nan\n",
      "Performance general en el reconocimiento de  Electronic :  nan\n",
      "Performance general en el reconocimiento de  Punk :  nan\n",
      "Performance general en el reconocimiento de  Latin :  nan\n",
      "Performance general en el reconocimiento de  Folk :  nan\n",
      "Performance general en el reconocimiento de  Reggae :  nan\n",
      "Performance general en el reconocimiento de  Jazz :  23.8095238095\n",
      "Performance general en el reconocimiento de  Blues :  nan\n",
      "Performance general en el reconocimiento de  World :  nan\n",
      "Performance general en el reconocimiento de  New :  nan\n",
      "Performance general en el reconocimiento de  Native :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "media_harmonica = 2 * ((precision * sensibilidad) / (precision + sensibilidad))\n",
    "\n",
    "for i in range(len(generos)):\n",
    "    print(\"Performance general en el reconocimiento de \", generos[i], ': ', media_harmonica[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Con el puntaje F1 dejamos de analizar por separado la sensibilidad/reminiscencia y la precisión y pasamos a ver los resultados que esperamos obtener, es decir, saber qué tan bien esta reconociendo nuestro modelo canciones pertenecientes a un género musical en y**.\n",
    "Y los números ya son más que esclarecedores: el reconocimiento de géneros musicales en la mayoría de los géneros musicales es pobrísimo pero intenta mejorar en el reconocimiento de canciones de Jazz.\n",
    "Esto indica algo muy importante a tener en cuenta cuando queremos entrenar un algoritmo de clasificación: **la cantidad de muestras que queremos reconocer debe ser mucha**. En este ejemplo nosotros utilizamos solamente un poco mas de 100 canciones para identificar géneros, cuando en un contexto más verídico es necesario contar con al menos más de 1000 canciones e idealmente más de 3000 o 6000 canciones para empezar a reconocer géneros de una forma un poco más correcta.\n",
    "**Necesitamos que las muestras sean miles y miles ya que debemos eliminar la barrera que genera la subjetividad y el sentido común a la hora de validar hipótesis sobre un conjunto de datos. Cuanto más grande es el sesgo humano a la hora de resolver un problema que se encargará de resolver un algoritmo de Machine Learning el objetivo debe pulirse con mayor cantidad de información, ya que el hallazgo de patrones basados en relaciones objetivas (y no subjetivas) debe ser mayor**.\n",
    "En el caso de reconocimiento de géneros deberiamos contar al menos con datos de 100 canciones que se presuponen que pertenecen a cada género (entrenaríamos mas de 1600 canciones, lo cual implica incrementar la precisión y sensibilidad para encontrar relaciones objetivas dentro del conjunto de datos). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "   #### 1. Uno de estos vectores de p minimiza el error de entrenamiento al intentar clasificar canciones de acuerdo al género musical contando con estos valores de y:\n",
    "   \n",
    "   #### y = [14,  1,  9, 15, 10, 15,  6, 14,  3,  1, 14,  5,  5,  3, 13, 10,  3, 1,  3,  0, 10,  7, 12, 12,  5, 14,  2,  7, 12, 10,  4,  3,  9, 14, 14,  5,  1, 14,  7, 14, 12, 14,  0, 12,  8,  7,  0, 14, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 13, 11,  6, 11, 12, 13,  1, 11, 11,  6, 11,  0, 11, 10, 11, 11, 11, 11, 15,  9,  9, 11, 11, 11, 11, 5, 15, 11,  0,  7, 14,  5,  7, 10, 12, 12, 13,  3, 10, 10,  7,  9, 5, 10,  4, 13,  7,  5,  1,  6,  0,  8, 10,  6, 11, 11, 11, 10,  5, 3, 12,  6,  1,  3,  6, 10,  3, 12,  1, 15, 11, 11]\n",
    "    \n",
    "    p = [12,  1,  9, 12, 10, 12,  6, 12,  3,  1, 12,  5,  5,  3, 12, 10,  3,\n",
    "            1,  3,  0, 10,  7, 12, 12,  5, 12,  2,  7, 12, 10,  4,  3,  9, 12,\n",
    "           12,  5,  1, 12,  7, 12, 12, 12,  0, 12,  8,  7,  0, 12, 11, 11, 11,\n",
    "           11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 11,  6, 11, 12, 12,  1, 11,\n",
    "           11,  6, 11,  0, 11, 10, 11, 11, 11, 11, 12,  9,  9, 11, 11, 11, 11,\n",
    "            5, 12, 11,  0,  7, 12,  5,  7, 10, 12, 12, 12,  3, 10, 10,  7,  9,\n",
    "            5, 10,  4, 12,  7,  5,  1,  6,  0,  8, 10,  6, 11, 11, 11, 10,  5,\n",
    "            3, 12,  6,  1,  3,  6, 10,  3, 12,  1, 12, 11, 11]\n",
    "\n",
    "    p = [12,  1,  9, 12, 10, 12,  6, 12,  3,  1, 12,  5,  5,  3, 12, 10,  3,\n",
    "            1,  3,  0, 10,  7, 12, 12,  5, 12,  2,  7, 12, 10,  4,  3,  9, 12,\n",
    "           12,  5,  1, 12,  7, 12, 12, 12,  0, 12,  8,  7,  0, 12, 11, 11, 11,\n",
    "           11, 11, 11, 14,14,14, 11, 11, 11, 12, 11,  6, 11, 12, 12,  1, 11,\n",
    "           11,  6, 11,  0, 11, 10, 11, 15,15,15, 12,  9,  9, 11, 11, 11, 11,\n",
    "            5, 12, 11,  0,  7, 12,  5,  7, 10, 12, 12, 12,  3, 10, 10,  7,  9,\n",
    "            5, 10,  4, 12,  7,  5,  1,  6,  0,  8, 10,  6, 11, 11, 11, 10,  5,\n",
    "            3, 12,  6,  1,  3,  6, 10,  3, 12,  1, 12, 12, 12]\n",
    "\n",
    "    p = [12,  1,  9, 12, 10, 12,  6, 12,  3,  1, 12,  5,  5,  3, 13, 10,  3,\n",
    "            1,  3,  0, 10,  7, 12, 12,  5, 12,  2,  7, 12, 10,  4,  3,  9, 12,\n",
    "           12,  5,  1, 14,  7, 12, 13, 12,  0, 12,  8,  7,  0, 12, 11, 11, 11,\n",
    "           11, 11, 11, 14,14,14, 11, 11, 11, 12, 11,  6, 11, 12, 13,  1, 11,\n",
    "           11,  6, 11,  0, 11, 10, 11, 15,15,15, 12,  9,  9, 11, 11, 11, 11,\n",
    "            5, 12, 11,  0,  7, 12,  5,  7, 10, 12, 12, 12,  3, 10, 10,  7,  9,\n",
    "            5, 10,  4, 12,  7,  5,  1,  6,  0,  8, 10,  6, 11, 11, 11, 10,  5,\n",
    "            3, 12,  6,  1,  3,  6, 10,  3, 12,  1, 12, 12, 12]\n",
    "    \n",
    "    Elige el vector que se corresponde con dicha descripción.\n",
    "    \n",
    "   #### Sugerencia:\n",
    "    \n",
    "       * Verifica que la precisión sea mayor al elegir el vector p de predicciones.\n",
    "       * Al minimizar el error la media harmónica es mayor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [14, 1, 9, 15, 10, 15, 6, 14, 3, 1, 14, 5, 5, 3, 13, 10, 3, 1, 3, 0, 10, 7, 12, 12, 5, 14, 2, 7, 12, 10, 4, 3, 9, 14, 14, 5, 1, 14, 7, 14, 12, 14, 0, 12, 8, 7, 0, 14, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 13, 11, 6, 11, 12, 13, 1, 11, 11, 6, 11, 0, 11, 10, 11, 11, 11, 11, 15, 9, 9, 11, 11, 11, 11, 5, 15, 11, 0, 7, 14, 5, 7, 10, 12, 12, 13, 3, 10, 10, 7, 9, 5, 10, 4, 13, 7, 5, 1, 6, 0, 8, 10, 6, 11, 11, 11, 10, 5, 3, 12, 6, 1, 3, 6, 10, 3, 12, 1, 15, 11, 11]\n",
    "\n",
    "#Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística\n",
    "\n",
    "### Objetivos de la regresión logística\n",
    "\n",
    "Ahora que hemos hecho una revisión conceptual extendida sobre el aprendizaje supervisado y la importancia de esta técnica para recoger información estadística podemos empezar a analizar información utilizando regresión logística. Se sabe que se puede utilizar la regresión lineal para hallar ajustes óptimos en un plano de variables x e y que permiten hallar diferentes tendencias o comportamientos a partir de los límites que genera una o varias líneas de regresión. ¿Qué ocurre cuando categorizamos a partir de estas tendencias? Ocurren más problemas que aciertos, ya que al hablar de regresión lineal nunca se habla de probabilidad, lo que es igual a utilizarde forma imprecisa e insuficiente un algoritmo interesante en un contexto de aprendizaje supervisado. **Todos las técnicas de clasificación son también algoritmos de regresión ya que deben hallar límites para encontrar subplanos a partir de una hiperplano de separación (una línea que divida el plano de forma óptima) y, además, todas las técnicas de clasificación requieren de outputs probabilísticos ya que es necesario medir la calidad de categorización de las variables y ser cuidadosos con la entropía que pueden presentar los datos. Es decir, los modelos de clasificación deben ser robustos no solo en el hallazgo de ajustes sino también en la categorización coherente de las muestras que se quieren clasificar**.\n",
    "Es por este motivo que al encontrarnos con problemas de clasificación el problema de regresión evoluciona de su forma simple y lineal a su forma **logística**. **La regresión es logística cuando sus outputs pueden ser distribuciones de probabilidad y tambien límites de decisión basados en la ecuación de regresión w * x + b**.\n",
    "La distribución de probabilidad de una regresión logística (la distribución que por cada muestra de datos exhibe la posibilidad de que una muestra pertenezca a una clase específica, siendo la columna de valor máximo aquella a la cual se le asigna la clase correspondiente) es, originalmente la **función sigmoide**. La función sigmoide simplemente describe el progreso de aprendizaje de una variable de datos luego de cada iteración de búsqueda de los coeficientes de regresión. Al estar esta función basada en la dependencia temporal del hallazgo óptimo de una clase válida para una muestra de datos y al devolver mediante el uso de la variable **e (epsilon)** un coeficiente continuo mayor a 0 y menor a 1 se convierte en la función predilecta para obtener clases a partir de la búsqueda de **probabilidades de que una variable sea de una categoría (su probabilidad es cercana a 1) o sea de una categoría aparte (la probabilidad es cercana a 0). La regresión logística entonces, a diferencia de la regresión lineal, estudia la relación entre las variables x para encontrar variables categóricas y*, mientras que la regresión lineal intenta hallar comportamientos a partir de vectores continuos en x e y.**\n",
    "\n",
    "##### ¿Cómo se calcula la función sigmoide?\n",
    "\n",
    "    * Para calcular la función sigmoide utilizaremos el producto entre valores x y coeficientes de pendiente/inclinación w como argumentos de medición de probabilidad. Este argumento será llamado x.\n",
    "    * Primero invertimos el signo de todos los valores en x\n",
    "    * Los valores con signo invertido en x serán la potencia a la cual se eleva epsilon, cuya elevación resultante es sumada a 1 para evitar discontinuidad en el resultado.\n",
    "    * Este resultado será el denominador de 1, por lo cual esta función exhibirá reciprocidad en el resultado (el valor resultante será proporcional a la posibilidad de no ser de otra clase, por lo que se descartarán los valores que no contengan mayor proporción que las demas).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades de los valores x de pertenecer positivamente o negativamente a su clase correspondiente:  [ 0.5         0.4875026   0.49000133  0.44472682  0.4294734   0.42555748\n",
      "  0.42555748  0.66818777  0.59868766  0.63181242  0.81757448]\n"
     ]
    }
   ],
   "source": [
    "#importamos numpy para utilizar la variable epsilon\n",
    "import numpy as np\n",
    "\n",
    "#programamos la función sigmoide\n",
    "sigmoid = lambda x: 1 / (1 + np.e ** (-1 * x))\n",
    "\n",
    "#introducimos nuestras variables x\n",
    "x = np.array([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.])\n",
    "\n",
    "#introducimos nuestro coeficiente w \n",
    "w = np.array([-1.,-0.5,-0.2,-0.74,-0.71,-0.6,-0.5,1,0.5,0.6,1.5])\n",
    "\n",
    "print(\"Probabilidades de los valores x de pertenecer positivamente o negativamente a su clase correspondiente: \", sigmoid(x * w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ¿Cómo calcular las variables de decisión?\n",
    "    * Las variables de decisión son aquellas que resuelven la ecuación w * x + b (la pendiente/theta, nuestro conjunto de datos x y la ordenada al origen). Para saber el valor de la pendiente se utiliza un método de descenso de gradiente logístico, el cual actualiza el valor de acuerdo a los costos presentados en cada iteración (el costo se calcula utilizando una función de error aplicado sobre la función sigmoide del producto de x y el valor presente de theta/w). Cuando la derivada desciende y la gradiente es óptima el error disminuye, encontrando así convergencia en el direccionamiento al direccionar la línea de ajuste. Al ser la diferencia entre los valores de theta actualizado y theta viejo menores al tamaño de aprendizaje la convergencia existe y se deja de actualizar los valores de la pendiente. Otra forma de obtener los valores de pendiente sin tomar en cuenta la convergencia de actualización de los datos es simplemente iterar unas cuantas veces con un for loop.\n",
    "    * La ordenada al origen se invirtiendo la mitad de la suma entre el mínimo y el máximo del producto (w veces x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x,y, lr):\n",
    "    thetas = [] #por cada categoría existente se calcula un vector w\n",
    "    for i in np.unique(y):\n",
    "        theta = [0.0 for i in range(x.shape[1])]\n",
    "        for epoch in range(30): #este proceso es iterativo por ende tenemos que aproximarnos a la convergencia utilizando una cantidad mínima de iteraciones\n",
    "            rmse = 0\n",
    "            for row in x[y == i]:\n",
    "                yhat = sigmoid(row.dot(theta)) #distribución de probabilidad\n",
    "                error = row[-1] - yhat \n",
    "                rmse += np.sqrt(np.mean((error**2))) #raiz media cuadrática del error\n",
    "                theta[0] = theta[0] + lr * error * yhat * (1.0 - yhat) #J, derivada de theta\n",
    "                for i in range(len(row)-1):\n",
    "                    theta[i + 1] = theta[i + 1] + lr * error * yhat * (1.0 - yhat) * row[i] #theta desplazado hacia donde el error se minimiza y se corrigen las probabilidades \n",
    "            if rmse < lr:\n",
    "                break\n",
    "        thetas.append(theta)\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ¿Cómo predecimos los resultados?\n",
    "    * Una vez obtenidos los coeficientes de theta, pasamos a resolver la ecuación de regresión y obtener la probabilidad de pertenencia a una categoría de acuerdo a la distribución de probabilidad. El índice con valor máximo en una distribución de probabilidad se corresponde con la categoría a asignar a la variable x_i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de datos x:  [[ 0.   0.1]\n",
      " [ 0.2  0.3]\n",
      " [ 0.4  0.5]\n",
      " [ 0.6  0.7]\n",
      " [ 0.8  0.9]]\n",
      "Pendiente de inclinación logística:  [[0.59999999999999987, 0.35999999999999993], [-0.26110328124039661, 1.0000312091237959]]\n",
      "Clases asignadas logísticamente:  [1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "decision = lambda x, w: -((x.dot(w.T).max() + x.dot(w.T).min())/2) + (x.dot(w.T)) #w * x + b\n",
    "\n",
    "def predict(x,w):\n",
    "    proba = sigmoid(decision(x,w)) #aplicamos la función sigmoide para obtener las probabilidades\n",
    "    return proba.argmax(axis=1) #buscamos máximas probabilidades fila por fila\n",
    "\n",
    "x = np.array([[0,0.1],[0.2,0.3],[0.4,0.5],[0.6,0.7],[0.8,0.9]])\n",
    "\n",
    "y = np.array([1,1,0,0,1])\n",
    "\n",
    "w = fit(x,y, lr = 12) #establecemos un factor de aprendizaje pequeño para que los descensos sean de a pequeños pasos\n",
    "\n",
    "print(\"Matriz de datos x: \", x)\n",
    "\n",
    "print(\"Pendiente de inclinación logística: \", w)\n",
    "\n",
    "p = predict(x,np.array(w))\n",
    "\n",
    "print (\"Clases asignadas logísticamente: \", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ¿Cómo visualizamos la regresión logística?\n",
    "    \n",
    "    * El procedimiento es similar al de la resolución de un problema de regresión lineal, con la única diferencia que la línea de ajuste logística es una función sigmoide de la línea de regresión lineal (w * x) + b. Esto es asi porque el valor máximo a considerar para asignar una clase es la variable de decisión con mayor probabilidad.\n",
    "    * Eligiendo los parámetros de aprendizaje adecuados, obtendremos una linea de ajuste que no da lugar a desclasificaciones: el ajuste no debe dar asignar una categoría que es opuesta a la región factible en la que se encuentran los datos limitados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8652606a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(x.min(),x.max(), len(x)), sigmoid(decision(x, np.array(w))).max(axis=1))\n",
    "plt.scatter(x[:,0],x[:,1], c=p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ¿Podemos evaluar la performance de nuestro modelo utilizando técnicas de validación cruzada?\n",
    "\n",
    "    Por supuesto que si, el indicador de que el modelo es válido será el incremento de la media harmónica de los datos de prueba. Si la media harmónica de los datos de prueba es mayor que la media harmónica de los datos de entrenamiento, simplemente hemos escogido los datos adecuados para testear la performance de nuestro y confirmar que podemos entrenar nueva información y clasificarla con éxito.\n",
    "    Ahora vamos a proceder a realizar regresión logística utilizando técnicas de validación cruzada, es decir, separando los datos entre datos de prueba y datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7 13 13 13 13 13 13 13\n",
      " 13 13 13 13  7  7  7 13 13  7 13  7  7  7  7  7  7  7  7  2  2  2  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  2  7 13 13 13 13  7  7 11  7  7  7  7  2  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7] [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 2 7 7 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "generos = ['Rock', 'Pop', 'Metal', 'samba', 'Rap', 'Electronic', 'experimental', 'Punk', 'Latin', 'Folk', 'Reggae', 'Jazz', 'Blues', 'cumbia', 'flamenco', 'Native']\n",
    "\n",
    "x = np.array([[  1.09258964e-02,   8.60257234e-01,   8.96178667e-03,\n",
    "          8.72081420e-03,   3.64535217e-01,   1.48036777e-10,\n",
    "          4.08074693e-02,   9.98116112e-01,   3.63949846e-04,\n",
    "          2.05294845e-04,   1.00000000e+00,   1.28593041e-01,\n",
    "          5.99088745e-05,   2.61188684e-01,   6.22195801e-02,\n",
    "          1.23675181e-01,   1.29367099e-01],[  1.69338725e-01,   9.10753840e-01,   1.19009463e-02,\n",
    "          4.49740413e-03,   3.03334838e-01,   1.43074691e-10,\n",
    "          3.38605597e-02,   9.97445355e-01,   2.28736281e-04,\n",
    "          1.29496695e-04,   1.00000000e+00,   4.68986384e-02,\n",
    "          1.06256292e-04,   1.77439434e-01,   3.97978387e-02,\n",
    "          4.28252054e-02,   8.47287444e-02],[  4.47067311e-02,   9.51426995e-01,   1.80222583e-02,\n",
    "          5.28139196e-03,   3.05344847e-01,   1.31023886e-10,\n",
    "          2.96770093e-02,   9.97319350e-01,   8.54099019e-04,\n",
    "          2.99017734e-04,   1.00000000e+00,   4.61422088e-02,\n",
    "          0.00000000e+00,   2.41427656e-01,   2.46286094e-02,\n",
    "          4.37631256e-02,   1.37814072e-01],[  2.30459551e-01,   9.74902244e-01,   1.45833199e-02,\n",
    "          8.61397423e-03,   3.62781358e-01,   1.50155971e-10,\n",
    "          3.54352739e-02,   9.98550199e-01,   5.37473921e-04,\n",
    "          7.59923484e-05,   1.00000000e+00,   8.09379728e-02,\n",
    "          2.13669499e-05,   9.56334436e-02,   3.67172294e-02,\n",
    "          8.01435681e-02,   6.57713925e-02],[  2.40091128e-01,   8.22608212e-01,   1.76171775e-02,\n",
    "          1.14641393e-02,   3.36865627e-01,   1.55087221e-10,\n",
    "          9.34424920e-02,   9.98822186e-01,   7.94379695e-04,\n",
    "          2.92804956e-04,   1.00000000e+00,   3.10136157e-02,\n",
    "          2.65540567e-04,   2.38821972e-01,   1.41763265e-02,\n",
    "          3.01164651e-02,   1.89523759e-01],[  1.52750386e-01,   8.01787664e-01,   2.32454876e-02,\n",
    "          1.50282330e-02,   3.52860771e-01,   1.61660157e-10,\n",
    "          1.90220332e-01,   9.99321360e-01,   5.63389854e-04,\n",
    "          1.01576181e-03,   1.00000000e+00,   7.41301059e-02,\n",
    "          2.85384964e-04,   1.33614998e-01,   4.52053293e-02,\n",
    "          7.18133452e-02,   1.34714558e-01],[  4.47145156e-02,   8.64396811e-01,   1.69509181e-02,\n",
    "          1.35464114e-02,   3.30839837e-01,   1.55868707e-10,\n",
    "          1.06418814e-01,   9.98979861e-01,   7.57195964e-04,\n",
    "          5.60079635e-04,   1.00000000e+00,   4.46293495e-02,\n",
    "          1.77890535e-04,   1.97852598e-01,   1.67189834e-02,\n",
    "          4.30150360e-02,   8.34109463e-02],[  1.32748419e-01,   7.61699689e-01,   4.27915815e-03,\n",
    "          1.07530195e-02,   3.80719474e-01,   1.43605849e-10,\n",
    "          1.27940815e-01,   9.98170068e-01,   1.05917293e-04,\n",
    "          1.37760994e-04,   1.00000000e+00,   9.22844175e-02,\n",
    "          2.99053452e-04,   1.14038451e-01,   4.52682926e-02,\n",
    "          8.51482604e-02,   5.96516206e-02],[  8.20647113e-01,   8.24928368e-01,   4.10156612e-03,\n",
    "          1.12425039e-02,   3.69898192e-01,   1.39170481e-10,\n",
    "          3.81485229e-02,   9.98052442e-01,   7.79731559e-04,\n",
    "          2.39541705e-04,   1.00000000e+00,   1.11195159e-01,\n",
    "          9.57592928e-05,   1.85418931e-01,   5.37516856e-02,\n",
    "          1.06449365e-01,   1.91842623e-01],[  2.17166576e-01,   8.03975363e-01,   6.56389117e-03,\n",
    "          1.30142635e-02,   3.60438900e-01,   1.51505281e-10,\n",
    "          7.16483314e-02,   9.98430879e-01,   4.43951205e-04,\n",
    "          4.34982748e-04,   1.00000000e+00,   4.08472012e-02,\n",
    "          4.36737812e-04,   3.56647976e-01,   2.08367958e-02,\n",
    "          3.78641922e-02,   1.02139419e-01],[  8.91631361e-02,   8.69112357e-01,   1.21949681e-02,\n",
    "          1.00979790e-02,   2.49194807e-01,   1.84568916e-10,\n",
    "          2.21650473e-01,   9.99462556e-01,   5.80291550e-04,\n",
    "          2.25254058e-03,   1.00000000e+00,   8.85022693e-02,\n",
    "          2.48695997e-04,   2.07830135e-01,   1.84441123e-02,\n",
    "          8.42428049e-02,   7.52578022e-02],[  1.20162216e-01,   7.61218207e-01,   2.99195345e-03,\n",
    "          1.50939418e-02,   3.80688736e-01,   1.59282171e-10,\n",
    "          1.67192559e-01,   9.98815714e-01,   8.02267153e-04,\n",
    "          4.41596992e-04,   1.00000000e+00,   9.37972769e-02,\n",
    "          4.20464223e-04,   2.22518241e-01,   4.96743258e-02,\n",
    "          8.86308238e-02,   1.00000000e+00],[  2.55030264e-01,   9.29181465e-01,   1.23512334e-02,\n",
    "          1.01289667e-02,   3.43601771e-01,   1.41329226e-10,\n",
    "          4.93890331e-02,   9.98022581e-01,   3.21132217e-04,\n",
    "          3.90023863e-04,   1.00000000e+00,   1.17246596e-01,\n",
    "          1.02735817e-04,   1.94157797e-01,   5.29511242e-02,\n",
    "          1.05056626e-01,   1.77442206e-01],[  4.30551612e-02,   8.17521556e-01,   2.16374323e-02,\n",
    "          9.95812881e-03,   3.70219454e-01,   1.59480540e-10,\n",
    "          6.06643761e-02,   9.99065933e-01,   7.29026472e-04,\n",
    "          7.50659384e-04,   1.00000000e+00,   9.68229955e-02,\n",
    "          1.25960880e-04,   8.20773022e-02,   6.00626195e-02,\n",
    "          9.09543735e-02,   9.04358343e-02],[  5.19102906e-01,   8.81992323e-01,   8.69451998e-03,\n",
    "          1.25907848e-02,   3.60681206e-01,   1.43445977e-10,\n",
    "          5.61514294e-02,   9.98331578e-01,   3.40287472e-04,\n",
    "          2.84361928e-04,   1.00000000e+00,   1.19515885e-01,\n",
    "          2.30726107e-04,   2.46701640e-01,   7.29839160e-02,\n",
    "          1.19012194e-01,   8.95434505e-02],[  2.95870712e-05,   8.54112253e-01,   2.73923158e-02,\n",
    "          6.48071660e-03,   3.42531100e-01,   1.76319959e-10,\n",
    "          6.77335810e-02,   9.98480541e-01,   2.98596623e-04,\n",
    "          1.73472176e-04,   1.00000000e+00,   2.19364599e-02,\n",
    "          5.50912979e-05,   9.36306945e-02,   1.03864129e-02,\n",
    "          2.07847109e-02,   8.38650439e-02],[  4.88151288e-02,   8.40459411e-01,   3.31422168e-03,\n",
    "          1.48980750e-02,   3.30034549e-01,   1.29757455e-10,\n",
    "          1.56813859e-01,   9.98665922e-01,   3.58315947e-04,\n",
    "          6.83748509e-04,   1.00000000e+00,   4.46293495e-02,\n",
    "          7.87668984e-04,   8.97774085e-02,   1.61614177e-02,\n",
    "          4.07424300e-02,   1.91742098e-01],[  2.22545299e-01,   8.46042199e-01,   2.70683979e-02,\n",
    "          1.21687324e-02,   3.22138318e-01,   1.64010805e-10,\n",
    "          1.01189874e-01,   9.98804677e-01,   6.16348501e-04,\n",
    "          5.13624411e-04,   1.00000000e+00,   8.39636914e-02,\n",
    "          3.79672823e-04,   4.99884760e-02,   2.29414514e-02,\n",
    "          8.20474949e-02,   7.93932005e-02],[  5.99342758e-03,   1.45208845e-10,   7.44097953e-01,\n",
    "          1.00000000e+00,   9.99076184e-01,   9.49641704e-01,\n",
    "          1.26770897e-06,   3.47988621e-01,   1.00000000e+00,\n",
    "          3.41091727e-02,   1.04400986e-03,   5.55521936e-02,\n",
    "          8.29988803e-02,   4.45635754e-01,   4.49664321e-02,\n",
    "          6.70475001e-03,   3.70356690e-04],[  1.34118749e-02,   1.66892389e-10,   7.43508262e-01,\n",
    "          1.00000000e+00,   9.99653116e-01,   8.86365637e-01,\n",
    "          1.28038606e-04,   3.93283285e-01,   1.13348214e-02,\n",
    "          1.00000000e+00,   6.34852267e-03,   3.42511346e-02,\n",
    "          1.77014331e-01,   1.38278111e-01,   2.62170389e-02,\n",
    "          2.27616760e-01,   5.42804693e-03],[  1.46056360e-02,   1.61961888e-10,   7.62264471e-01,\n",
    "          1.00000000e+00,   1.00000000e+00,   9.51615535e-01,\n",
    "          2.53541793e-06,   1.98501203e-01,   7.05731255e-01,\n",
    "          4.26518144e-02,   6.37489583e-03,   7.38275340e-02,\n",
    "          5.76208763e-01,   5.66765423e-01,   1.23991879e-01,\n",
    "          9.75184100e-03,   4.96632331e-04],[  1.20458361e-02,   1.83868587e-10,   1.00000000e+00,\n",
    "          1.00000000e+00,   9.99163609e-01,   7.39360870e-01,\n",
    "          4.22569656e-07,   2.66634704e-01,   2.84216526e-01,\n",
    "          2.60891090e-02,   1.21186614e-02,   8.48411498e-02,\n",
    "          1.00000000e+00,   0.00000000e+00,   2.62781460e-01,\n",
    "          5.09586042e-03,   7.15561742e-06],[  1.08562531e-02,   4.75640638e-11,   8.95900362e-01,\n",
    "          1.00000000e+00,   9.98854417e-01,   7.06534392e-01,\n",
    "          5.49340552e-06,   1.48967003e-01,   2.03052358e-03,\n",
    "          6.63851430e-02,   1.09471691e-02,   6.28139183e-02,\n",
    "          3.14056843e-01,   3.41925078e-01,   9.08681385e-01,\n",
    "          1.30413365e-02,   9.64357055e-04],[  1.35601142e-02,   1.74980919e-10,   8.45245930e-01,\n",
    "          1.00000000e+00,   9.99227212e-01,   6.96956229e-01,\n",
    "          1.26770897e-06,   2.86001022e-01,   1.91615707e-01,\n",
    "          3.45196979e-02,   1.41028994e-02,   6.20877458e-02,\n",
    "          7.99461596e-01,   1.93428789e-01,   2.47243272e-01,\n",
    "          8.38032510e-03,   2.21108578e-04],[  1.21397504e-02,   0.00000000e+00,   9.12193964e-01,\n",
    "          1.00000000e+00,   9.98809577e-01,   7.57187890e-01,\n",
    "          0.00000000e+00,   0.00000000e+00,   3.30136791e-06,\n",
    "          2.49085351e-02,   8.03437886e-03,   7.96369138e-02,\n",
    "          1.82736696e-01,   3.20405016e-01,   1.00000000e+00,\n",
    "          5.38237960e-03,   2.20080334e-04],[  1.11018846e-02,   1.38159706e-10,   8.29297646e-01,\n",
    "          1.00000000e+00,   9.99081668e-01,   7.41318052e-01,\n",
    "          7.18368415e-06,   2.54921211e-01,   2.13954836e-02,\n",
    "          7.91991055e-02,   1.07506300e-02,   8.24205749e-02,\n",
    "          3.93418016e-01,   1.00000000e+00,   6.64634531e-01,\n",
    "          1.73518608e-02,   9.40157701e-04],[  2.67062914e-03,   1.30479960e-10,   7.56156030e-01,\n",
    "          1.00000000e+00,   9.99205082e-01,   1.00000000e+00,\n",
    "          1.64802166e-05,   2.85642859e-01,   6.53428755e-02,\n",
    "          1.50737008e-01,   0.00000000e+00,   8.20574887e-02,\n",
    "          6.24405062e-02,   3.06216437e-01,   8.11487534e-03,\n",
    "          3.33527885e-02,   1.78697545e-03],[  8.32190902e-03,   1.54603552e-10,   7.36428023e-01,\n",
    "          1.00000000e+00,   9.99226296e-01,   9.67141366e-01,\n",
    "          4.22569656e-07,   3.62507785e-01,   1.10245389e-01,\n",
    "          2.83213710e-02,   1.31815217e-03,   6.00302572e-02,\n",
    "          6.94242685e-02,   1.94803602e-01,   1.47472421e-02,\n",
    "          4.34679986e-03,   3.05519308e-04],[  1.36162843e-02,   1.62074132e-10,   7.44735464e-01,\n",
    "          1.00000000e+00,   9.99155274e-01,   8.58239316e-01,\n",
    "          5.11309283e-05,   3.85450295e-01,   2.26827449e-02,\n",
    "          4.12525686e-01,   1.08660088e-02,   5.88199697e-02,\n",
    "          1.73222275e-01,   2.57972390e-01,   3.89717186e-02,\n",
    "          9.50355466e-02,   5.70302708e-03],[  4.79464763e-01,   8.87442623e-01,   1.04082660e-02,\n",
    "          1.45400960e-02,   3.61393735e-01,   1.35042755e-10,\n",
    "          1.42589170e-01,   9.98591830e-01,   5.16065107e-04,\n",
    "          5.67119347e-04,   1.00000000e+00,   1.31618759e-01,\n",
    "          3.69026804e-04,   2.47917658e-01,   4.29888217e-02,\n",
    "          1.24210231e-01,   1.10834121e-01],[  1.08190216e-01,   1.00000000e+00,   1.69530960e-02,\n",
    "          9.98875974e-03,   3.20264510e-01,   1.43172085e-10,\n",
    "          3.69154816e-02,   9.98577997e-01,   7.63956643e-04,\n",
    "          1.35227320e-04,   1.00000000e+00,   5.90015129e-02,\n",
    "          4.95097002e-05,   9.13489375e-02,   2.63790432e-02,\n",
    "          5.45888138e-02,   1.00340052e-01],[  2.86757223e-01,   8.96420594e-01,   1.98021681e-02,\n",
    "          1.26005582e-02,   3.42286675e-01,   1.30423922e-10,\n",
    "          7.21503169e-02,   9.98642020e-01,   5.36347141e-04,\n",
    "          1.85724401e-04,   1.00000000e+00,   4.68986384e-02,\n",
    "          3.75829905e-04,   1.64499665e-01,   1.51339186e-02,\n",
    "          4.38165296e-02,   1.14495013e-01],[  1.09248000e-02,   1.41323286e-10,   7.60988771e-01,\n",
    "          1.00000000e+00,   9.99770824e-01,   9.26477233e-01,\n",
    "          2.61993187e-05,   3.36255519e-01,   1.56592306e-01,\n",
    "          2.21927950e-01,   4.72801112e-03,   7.67322239e-02,\n",
    "          3.41673873e-01,   1.93217065e-01,   4.78917125e-02,\n",
    "          5.43358414e-02,   2.48327184e-03],[  9.71571932e-03,   1.53423385e-10,   7.47506697e-01,\n",
    "          1.00000000e+00,   9.99209201e-01,   8.81656482e-01,\n",
    "          2.87347366e-05,   3.91741241e-01,   1.53912084e-01,\n",
    "          2.41226903e-01,   9.19757359e-03,   7.38275340e-02,\n",
    "          1.69407143e-01,   1.00769736e-01,   2.56374181e-02,\n",
    "          5.24267910e-02,   4.05636618e-03],[  5.98130401e-02,   9.61093600e-01,   4.41423784e-03,\n",
    "          1.02802949e-02,   3.54971004e-01,   1.34839473e-10,\n",
    "          4.04226314e-02,   9.98169482e-01,   4.93529513e-04,\n",
    "          1.14179469e-04,   1.00000000e+00,   2.57186082e-02,\n",
    "          1.09074966e-04,   1.47558953e-01,   8.41553279e-03,\n",
    "          2.35866540e-02,   2.03022288e-01],[  7.89248206e-03,   1.49754764e-10,   8.33755134e-01,\n",
    "          1.00000000e+00,   9.99169225e-01,   8.20836171e-01,\n",
    "          3.21152938e-05,   3.88389016e-01,   6.13997108e-02,\n",
    "          2.68311263e-01,   1.01987901e-02,   2.68683812e-02,\n",
    "          2.25409215e-01,   2.57914876e-01,   4.88828429e-02,\n",
    "          5.96672585e-02,   3.51680096e-03],[  2.13894332e-01,   8.31589798e-01,   1.72424274e-02,\n",
    "          1.12005637e-02,   3.66713784e-01,   1.51865159e-10,\n",
    "          6.42672211e-02,   9.98887362e-01,   2.11834585e-04,\n",
    "          2.17611984e-04,   1.00000000e+00,   7.63993949e-02,\n",
    "          1.77530136e-04,   1.52530423e-01,   2.10667917e-02,\n",
    "          7.42488907e-02,   1.05110211e-01],[  0.00000000e+00,   9.17959389e-01,   2.33554960e-02,\n",
    "          1.20312930e-02,   3.21918827e-01,   1.32687028e-10,\n",
    "          9.93655430e-02,   9.98668818e-01,   3.89865779e-04,\n",
    "          9.29196959e-04,   1.00000000e+00,   1.00000000e+00,\n",
    "          3.84440579e-04,   2.11268067e-01,   5.50042665e-01,\n",
    "          1.00000000e+00,   6.74487253e-02],[  0.00000000e+00,   9.42225096e-01,   1.82104559e-02,\n",
    "          1.15023096e-02,   3.30026300e-01,   1.33322298e-10,\n",
    "          7.56739517e-02,   9.98284796e-01,   0.00000000e+00,\n",
    "          7.83802860e-04,   1.00000000e+00,   9.56127080e-01,\n",
    "          2.29119784e-04,   1.82837664e-01,   4.94300502e-01,\n",
    "          9.27508638e-01,   1.50060122e-01],[  0.00000000e+00,   8.33112728e-01,   1.11736931e-02,\n",
    "          1.41612560e-02,   3.21438979e-01,   1.07753140e-10,\n",
    "          2.85874038e-01,   9.98348476e-01,   0.00000000e+00,\n",
    "          8.32291673e-04,   1.00000000e+00,   5.96066566e-01,\n",
    "          9.99511309e-04,   2.10863509e-01,   1.80404609e-01,\n",
    "          5.79271945e-01,   7.28891693e-02],[  1.38258112e-02,   8.70217438e-01,   2.48767298e-02,\n",
    "          1.33693177e-02,   3.07266443e-01,   1.48479062e-10,\n",
    "          1.34483332e-01,   9.98937545e-01,   4.32683408e-04,\n",
    "          4.27007898e-04,   1.00000000e+00,   5.29500756e-03,\n",
    "          6.33294590e-04,   3.63250139e-01,   2.54158399e-03,\n",
    "          4.44798627e-03,   7.40428549e-02],[  5.86180351e-02,   7.62235148e-01,   1.29540951e-02,\n",
    "          0.00000000e+00,   3.24730921e-01,   1.75591208e-10,\n",
    "          3.30631961e-02,   9.97441048e-01,   8.04520712e-04,\n",
    "          2.74969594e-06,   1.00000000e+00,   3.63086233e-02,\n",
    "          1.83582664e-05,   5.39565211e-01,   1.60442969e-02,\n",
    "          3.53840939e-02,   1.50224070e-01],[  5.03800249e-04,   9.36585901e-01,   5.33029981e-02,\n",
    "          5.04424642e-03,   1.81710067e-01,   1.70017000e-10,\n",
    "          1.15234509e-01,   9.99968299e-01,   5.20572226e-04,\n",
    "          1.60795067e-03,   1.00000000e+00,   3.02571861e-03,\n",
    "          1.64937357e-04,   4.47394572e-01,   1.16960014e-03,\n",
    "          1.75811401e-03,   0.00000000e+00],[  2.30507770e-01,   7.47549158e-01,   1.26095915e-02,\n",
    "          1.42361493e-02,   3.82914241e-01,   1.67543812e-10,\n",
    "          1.51385767e-01,   9.98917508e-01,   5.39727481e-04,\n",
    "          8.84624914e-04,   1.00000000e+00,   6.27836611e-02,\n",
    "          2.90321694e-04,   2.82009996e-01,   3.09243398e-02,\n",
    "          6.25830142e-02,   1.08402540e-01],[  9.21527945e-04,   8.68476668e-01,   3.24882405e-02,\n",
    "          7.65189402e-03,   2.95633094e-01,   1.55345958e-10,\n",
    "          1.60135357e-01,   9.99963289e-01,   4.37190527e-04,\n",
    "          3.36893998e-03,   1.00000000e+00,   3.02571861e-03,\n",
    "          4.42121432e-04,   5.33466853e-01,   1.14675241e-03,\n",
    "          2.50202156e-03,   1.10202279e-02],[  9.31307954e-02,   7.22735586e-01,   3.22230756e-03,\n",
    "          5.34110928e-03,   3.79567051e-01,   1.67582809e-10,\n",
    "          3.28122795e-02,   9.98103653e-01,   5.13811547e-04,\n",
    "          3.04941855e-05,   1.00000000e+00,   4.53857791e-03,\n",
    "          3.77202183e-05,   3.80093834e-01,   1.74901012e-03,\n",
    "          2.29461282e-03,   9.19904871e-02],[  1.77877622e-02,   7.68065889e-01,   1.07752034e-02,\n",
    "          8.71057887e-03,   1.31034421e-01,   0.00000000e+00,\n",
    "          8.91795604e-01,   9.97891012e-01,   6.32123417e-04,\n",
    "          3.26263825e-03,   1.00000000e+00,   2.26928896e-03,\n",
    "          3.02989198e-03,   4.13647899e-01,   1.29140620e-03,\n",
    "          2.00686395e-03,   0.00000000e+00],[  2.43781811e-02,   7.70769267e-01,   3.83116415e-02,\n",
    "          1.28777939e-02,   3.03208914e-01,   1.93457111e-10,\n",
    "          1.67068230e-01,   9.99708370e-01,   7.29026472e-04,\n",
    "          9.42176967e-04,   1.00000000e+00,   4.68986384e-02,\n",
    "          2.49134906e-04,   1.01678439e-01,   1.91828643e-02,\n",
    "          4.59582849e-02,   1.08879133e-01],[  6.87603334e-02,   9.38280489e-01,   9.16572090e-03,\n",
    "          6.64662243e-03,   2.88203326e-01,   1.37834605e-10,\n",
    "          5.15975828e-02,   9.97395144e-01,   1.38593904e-04,\n",
    "          9.70423240e-04,   1.00000000e+00,   1.51285930e-03,\n",
    "          5.23708297e-05,   7.00373130e-01,   6.21691154e-04,\n",
    "          6.93548571e-04,   0.00000000e+00],[  2.21450736e-01,   9.68730909e-01,   1.65161460e-02,\n",
    "          3.04957973e-04,   0.00000000e+00,   2.76626222e-11,\n",
    "          1.00000000e+00,   9.96962618e-01,   5.40854260e-04,\n",
    "          3.94679938e-03,   1.00000000e+00,   3.02571861e-03,\n",
    "          2.19438250e-03,   6.70323820e-01,   1.12592958e-03,\n",
    "          1.76654621e-03,   0.00000000e+00],[  1.79730367e-01,   9.59410222e-01,   6.33321323e-02,\n",
    "          1.16774908e-02,   3.19848328e-01,   1.67681868e-10,\n",
    "          9.70324308e-02,   9.99521309e-01,   3.36907133e-04,\n",
    "          3.91809473e-04,   1.00000000e+00,   3.02571861e-03,\n",
    "          2.59252821e-04,   1.44999387e-01,   0.00000000e+00,\n",
    "          1.81713942e-03,   0.00000000e+00],[  1.05545957e-02,   8.07143807e-01,   5.54220379e-03,\n",
    "          1.41812678e-02,   3.58095929e-01,   1.45162382e-10,\n",
    "          1.60050913e-01,   9.98422752e-01,   6.10714602e-04,\n",
    "          2.84099112e-04,   1.00000000e+00,   6.95915280e-02,\n",
    "          6.12079950e-04,   2.47256505e-01,   2.88872947e-02,\n",
    "          6.80721895e-02,   1.12055323e-01],[  2.35477174e-01,   8.98196257e-01,   1.50569234e-02,\n",
    "          1.32620144e-02,   3.65860832e-01,   1.46578416e-10,\n",
    "          1.33464712e-01,   9.98630551e-01,   6.70433927e-04,\n",
    "          2.74523984e-04,   1.00000000e+00,   8.01815431e-02,\n",
    "          1.37572993e-04,   1.00280030e-01,   3.69079644e-02,\n",
    "          7.74159677e-02,   1.43236336e-01],[  1.73353057e-01,   8.91465240e-01,   2.06763190e-02,\n",
    "          1.21465343e-02,   3.61918365e-01,   1.37021200e-10,\n",
    "          1.32045087e-01,   9.98509584e-01,   1.29579667e-04,\n",
    "          2.63213723e-04,   1.00000000e+00,   4.99243570e-02,\n",
    "          2.05876285e-04,   7.42764742e-02,   2.41898672e-02,\n",
    "          4.66509651e-02,   1.79750581e-01],[  4.58110280e-02,   8.20318984e-01,   1.22539054e-02,\n",
    "          1.70262167e-02,   3.37660670e-01,   1.54370350e-10,\n",
    "          2.89347337e-01,   9.99329655e-01,   3.89865779e-04,\n",
    "          7.03691546e-04,   1.00000000e+00,   4.46293495e-02,\n",
    "          2.76035347e-04,   1.31398473e-01,   1.39216907e-02,\n",
    "          4.32686041e-02,   1.35578395e-01],[  2.17091182e-01,   9.17167509e-01,   1.88676369e-02,\n",
    "          1.37584231e-02,   3.51462622e-01,   1.43569406e-10,\n",
    "          1.12291590e-01,   9.99277760e-01,   6.18602060e-04,\n",
    "          1.19126969e-03,   1.00000000e+00,   2.64750378e-02,\n",
    "          3.86144668e-04,   2.75490645e-01,   1.31518437e-02,\n",
    "          2.41060743e-02,   2.75835407e-01],[  1.19313287e-01,   9.17375217e-01,   2.86576781e-02,\n",
    "          1.00601118e-02,   3.40621054e-01,   1.42261730e-10,\n",
    "          7.26299923e-02,   9.98315963e-01,   3.88739000e-04,\n",
    "          1.74287515e-04,   1.00000000e+00,   5.82450832e-02,\n",
    "          9.09776036e-05,   1.10155102e-01,   4.36996809e-02,\n",
    "          5.25396629e-02,   9.50827439e-02],[  7.66725191e-02,   9.01772907e-01,   3.91270196e-02,\n",
    "          1.13833172e-02,   3.32231645e-01,   1.46887308e-10,\n",
    "          9.87254017e-02,   9.98297991e-01,   4.70993918e-04,\n",
    "          6.00048174e-04,   1.00000000e+00,   6.80786687e-02,\n",
    "          3.92765396e-04,   1.76549619e-01,   3.57383376e-02,\n",
    "          6.52570688e-02,   7.11197606e-02],[  4.24591829e-02,   7.86013058e-01,   5.38141111e-03,\n",
    "          1.55564418e-02,   3.35969061e-01,   1.32155897e-10,\n",
    "          1.59212126e-01,   9.98683313e-01,   5.26206124e-04,\n",
    "          6.45499382e-04,   1.00000000e+00,   4.31164902e-02,\n",
    "          7.85901552e-04,   8.91299332e-02,   1.86664515e-02,\n",
    "          3.95332912e-02,   1.83121220e-01],[  2.70152290e-01,   6.42825469e-01,   0.00000000e+00,\n",
    "          1.83573386e-02,   3.41925925e-01,   1.71894943e-10,\n",
    "          3.84735685e-01,   9.99250346e-01,   7.65083422e-04,\n",
    "          8.49769169e-04,   1.00000000e+00,   6.27836611e-02,\n",
    "          2.86996133e-04,   4.02156220e-02,   5.76286744e-05,\n",
    "          6.16222922e-02,   8.11199017e-02],[  3.32042344e-02,   9.82275305e-01,   2.17358061e-02,\n",
    "          9.77781428e-03,   3.35499694e-01,   1.44878165e-10,\n",
    "          4.52793833e-02,   9.98467821e-01,   4.65360020e-04,\n",
    "          5.93778201e-05,   1.00000000e+00,   1.04387292e-01,\n",
    "          7.55028448e-05,   8.28659677e-02,   4.43833389e-02,\n",
    "          1.01820202e-01,   6.35999309e-02],[  1.45199734e-02,   2.34174791e-10,   8.16635428e-01,\n",
    "          1.00000000e+00,   9.99623435e-01,   7.93624853e-01,\n",
    "          2.23961918e-05,   2.37515910e-01,   2.94250668e-01,\n",
    "          1.93949178e-01,   8.50458232e-03,   8.47201210e-02,\n",
    "          6.12990668e-01,   9.51644120e-04,   1.42645820e-01,\n",
    "          4.37632710e-02,   2.30802736e-03],[  1.45199734e-02,   2.34174791e-10,   8.16635428e-01,\n",
    "          1.00000000e+00,   9.99623435e-01,   7.93624853e-01,\n",
    "          2.23961918e-05,   2.37515910e-01,   2.94250668e-01,\n",
    "          1.93949178e-01,   8.50458232e-03,   8.47201210e-02,\n",
    "          6.12990668e-01,   9.51644120e-04,   1.42645820e-01,\n",
    "          4.37632710e-02,   2.30802736e-03],[  1.05427703e-02,   1.60934044e-10,   7.47788681e-01,\n",
    "          1.00000000e+00,   9.98978142e-01,   7.37342425e-01,\n",
    "          4.43698138e-05,   3.94521724e-01,   2.34944224e-02,\n",
    "          3.61128639e-01,   1.16030175e-02,   5.57942511e-02,\n",
    "          3.29879128e-01,   2.48636544e-01,   6.20048716e-02,\n",
    "          7.95908977e-02,   3.44257606e-03],[  1.19332066e-02,   1.53667079e-10,   7.49484900e-01,\n",
    "          1.00000000e+00,   9.99199123e-01,   8.92153752e-01,\n",
    "          3.00024456e-05,   3.64344672e-01,   1.89054550e-01,\n",
    "          2.50979263e-01,   1.01046632e-02,   5.26475038e-02,\n",
    "          1.84330349e-01,   7.07016502e-02,   3.78585722e-02,\n",
    "          5.67633204e-02,   2.53219411e-03],[  5.86180351e-02,   7.62235148e-01,   1.29540951e-02,\n",
    "          0.00000000e+00,   3.24730921e-01,   1.75591208e-10,\n",
    "          3.30631961e-02,   9.97441048e-01,   8.04520712e-04,\n",
    "          2.74969594e-06,   1.00000000e+00,   3.63086233e-02,\n",
    "          1.83582664e-05,   5.39565211e-01,   1.60442969e-02,\n",
    "          3.53840939e-02,   1.50224070e-01],[  3.35109876e-02,   8.73414283e-01,   1.56122508e-02,\n",
    "          9.26378787e-03,   3.41338848e-01,   1.46888612e-10,\n",
    "          3.62140804e-02,   9.98076316e-01,   1.90425771e-04,\n",
    "          1.60863496e-04,   1.00000000e+00,   6.50529501e-02,\n",
    "          3.64982654e-05,   1.84039547e-01,   3.23384858e-02,\n",
    "          5.96738218e-02,   2.06268375e-01],[  1.58519836e-03,   8.87859083e-01,   1.26862897e-02,\n",
    "          1.17129589e-02,   3.35388742e-01,   1.21192778e-10,\n",
    "          1.95726095e-01,   9.98110896e-01,   6.99730199e-04,\n",
    "          5.37898154e-04,   1.00000000e+00,   0.00000000e+00,\n",
    "          4.32740498e-04,   3.41081305e-01,   2.09558816e-04,\n",
    "          3.83665167e-04,   0.00000000e+00],[  2.98855738e-02,   7.83347193e-01,   4.85094365e-02,\n",
    "          8.28423518e-03,   1.96121207e-01,   1.76679948e-10,\n",
    "          1.07599288e-01,   1.00000000e+00,   5.87052228e-04,\n",
    "          8.90985775e-05,   1.00000000e+00,   5.67322239e-02,\n",
    "          1.79759336e-04,   7.74356692e-02,   2.78490569e-02,\n",
    "          5.28572549e-02,   1.06103679e-01],[  1.77626384e-03,   8.70828890e-01,   9.90608292e-03,\n",
    "          1.13689788e-02,   3.46832447e-01,   1.53488916e-10,\n",
    "          5.97352193e-02,   9.97973193e-01,   4.72120698e-04,\n",
    "          1.59244382e-04,   1.00000000e+00,   8.62329803e-02,\n",
    "          1.24802723e-03,   1.78197437e-01,   5.57164502e-02,\n",
    "          8.48260729e-02,   1.87593420e-01],[  2.34218617e-01,   8.67440924e-01,   1.77424475e-03,\n",
    "          8.93225065e-03,   3.30646627e-01,   1.28834249e-10,\n",
    "          1.53674302e-01,   9.98084156e-01,   3.44794591e-04,\n",
    "          7.44162611e-04,   1.00000000e+00,   4.31164902e-02,\n",
    "          1.75693899e-04,   1.68032865e-01,   1.56475472e-02,\n",
    "          3.82071481e-02,   1.25762875e-01],[  1.14779495e-01,   7.15417095e-01,   1.57126128e-02,\n",
    "          1.46907122e-02,   3.35641032e-01,   1.92114241e-10,\n",
    "          4.29127106e-01,   9.98379695e-01,   6.74941046e-04,\n",
    "          2.06521819e-03,   1.00000000e+00,   6.50529501e-02,\n",
    "          1.19953299e-03,   3.41346639e-01,   3.59130325e-02,\n",
    "          6.44707011e-02,   2.29148084e-01],[  2.23458053e-03,   6.97069399e-01,   4.92822696e-03,\n",
    "          1.44849365e-02,   3.81415803e-01,   1.88241506e-10,\n",
    "          7.52688847e-02,   9.98481859e-01,   1.83665093e-04,\n",
    "          5.27996163e-04,   1.00000000e+00,   0.00000000e+00,\n",
    "          3.50398197e-04,   3.29483019e-01,   2.30514698e-04,\n",
    "          0.00000000e+00,   0.00000000e+00],[  2.33641630e-01,   8.31521019e-01,   2.70927946e-02,\n",
    "          1.35575452e-02,   3.34162096e-01,   1.49458862e-10,\n",
    "          1.57133240e-01,   9.98461011e-01,   5.25079344e-04,\n",
    "          1.15496588e-03,   1.00000000e+00,   5.82450832e-02,\n",
    "          5.39607329e-04,   1.26108550e-01,   2.08615801e-02,\n",
    "          5.52694267e-02,   8.13513734e-02],[  3.76456752e-02,   7.97962317e-01,   9.31149153e-03,\n",
    "          1.40233220e-02,   3.30110499e-01,   9.67129155e-11,\n",
    "          3.13312922e-01,   9.99069302e-01,   5.90432567e-04,\n",
    "          7.06509656e-04,   1.00000000e+00,   1.13464448e-01,\n",
    "          5.48919786e-04,   1.02205670e-01,   2.02867902e-02,\n",
    "          1.08129328e-01,   6.21805221e-02],[  3.62357116e-01,   9.08260440e-01,   4.73796995e-03,\n",
    "          1.39728562e-02,   3.57692007e-01,   1.28216826e-10,\n",
    "          6.80540978e-02,   9.98581615e-01,   4.03387136e-04,\n",
    "          6.06651039e-04,   1.00000000e+00,   1.39183056e-01,\n",
    "          3.84403134e-04,   1.28330245e-01,   6.51149536e-02,\n",
    "          1.37123989e-01,   1.25783954e-01],[  5.84856977e-01,   8.18808762e-01,   8.55574028e-03,\n",
    "          1.43060539e-02,   3.78603778e-01,   1.85014032e-10,\n",
    "          9.21817670e-02,   9.99034017e-01,   6.86208843e-04,\n",
    "          1.87565627e-04,   1.00000000e+00,   9.45537065e-02,\n",
    "          1.74827064e-04,   9.29005123e-02,   4.04937486e-02,\n",
    "          8.93017893e-02,   1.29300656e-01],[  1.00857108e-01,   7.26337266e-01,   2.98748655e-03,\n",
    "          1.54245978e-02,   3.85320661e-01,   1.47832524e-10,\n",
    "          1.49546332e-01,   9.98760599e-01,   4.37190527e-04,\n",
    "          4.01224940e-04,   1.00000000e+00,   1.00605144e-01,\n",
    "          3.79953757e-04,   1.48262591e-01,   4.37631348e-02,\n",
    "          9.35947567e-02,   5.04513749e-02],[  1.79501828e-01,   8.19048509e-01,   8.06492886e-03,\n",
    "          1.55154691e-02,   3.86532842e-01,   1.49205898e-10,\n",
    "          8.08314419e-02,   9.98947731e-01,   4.73247478e-04,\n",
    "          1.24104642e-03,   1.00000000e+00,   7.33736762e-02,\n",
    "          2.79310260e-04,   1.78549733e-01,   3.10837359e-02,\n",
    "          6.94829548e-02,   8.11777600e-02],[  1.43131137e-01,   8.13567159e-01,   1.21729915e-02,\n",
    "          1.27516317e-02,   3.61070029e-01,   1.66356096e-10,\n",
    "          6.80626913e-02,   9.98701416e-01,   4.58599342e-04,\n",
    "          8.87879177e-04,   1.00000000e+00,   7.48865356e-02,\n",
    "          2.09376590e-04,   1.50893079e-01,   2.12035420e-02,\n",
    "          7.41787922e-02,   1.28700362e-01],[  3.53200438e-01,   9.10011422e-01,   1.50288275e-02,\n",
    "          1.31131650e-02,   3.48928795e-01,   1.39297157e-10,\n",
    "          1.00680430e-01,   9.98540448e-01,   5.41981040e-04,\n",
    "          3.44025737e-04,   1.00000000e+00,   8.16944024e-02,\n",
    "          5.28915070e-04,   2.02869340e-01,   3.99936167e-02,\n",
    "          7.96915556e-02,   1.57068004e-01],[  2.69410683e-01,   7.73939640e-01,   1.40962316e-02,\n",
    "          1.55271096e-02,   3.10432189e-01,   1.52413276e-10,\n",
    "          3.59585138e-01,   9.98743091e-01,   7.47054947e-04,\n",
    "          2.85451395e-03,   1.00000000e+00,   9.75794251e-02,\n",
    "          6.68139648e-04,   1.28161660e-01,   4.18143184e-02,\n",
    "          9.03509369e-02,   1.47626283e-01],[  7.28096864e-01,   9.23862383e-01,   3.22444220e-02,\n",
    "          1.17328550e-02,   3.15095140e-01,   1.36355066e-10,\n",
    "          1.78950848e-01,   9.99061162e-01,   4.25922730e-04,\n",
    "          2.50243241e-04,   1.00000000e+00,   8.92586989e-02,\n",
    "          3.06624717e-04,   4.19945424e-02,   4.48335370e-02,\n",
    "          8.53604745e-02,   7.28939480e-02],[  1.52517291e-01,   8.17699272e-01,   1.24596406e-02,\n",
    "          1.40074125e-02,   3.33910505e-01,   1.33028116e-10,\n",
    "          2.92084966e-01,   9.98336028e-01,   7.01983759e-04,\n",
    "          8.16080055e-04,   1.00000000e+00,   6.05143722e-02,\n",
    "          6.87920504e-04,   1.74851457e-01,   2.34947673e-02,\n",
    "          5.64523142e-02,   7.48782803e-02],[  4.25944779e-01,   8.14604491e-01,   1.79609838e-02,\n",
    "          1.41449136e-02,   3.33271098e-01,   1.51443691e-10,\n",
    "          1.51445435e-01,   9.98299009e-01,   4.57472562e-04,\n",
    "          9.68763723e-04,   1.00000000e+00,   1.27080182e-01,\n",
    "          4.68302318e-04,   1.48678135e-01,   6.13334589e-02,\n",
    "          1.22879861e-01,   7.87521655e-02],[  4.88151288e-02,   8.40459411e-01,   3.31422168e-03,\n",
    "          1.48980750e-02,   3.30034549e-01,   1.29757455e-10,\n",
    "          1.56813859e-01,   9.98665922e-01,   3.58315947e-04,\n",
    "          6.83748509e-04,   1.00000000e+00,   4.46293495e-02,\n",
    "          7.87668984e-04,   8.97774085e-02,   1.61614177e-02,\n",
    "          4.07424300e-02,   1.91742098e-01],[  2.40091128e-01,   8.22608212e-01,   1.76171775e-02,\n",
    "          1.14641393e-02,   3.36865627e-01,   1.55087221e-10,\n",
    "          9.34424920e-02,   9.98822186e-01,   7.94379695e-04,\n",
    "          2.92804956e-04,   1.00000000e+00,   3.10136157e-02,\n",
    "          2.65540567e-04,   2.38821972e-01,   1.41763265e-02,\n",
    "          3.01164651e-02,   1.89523759e-01],[  1.40671288e-02,   8.77062627e-01,   1.74342129e-02,\n",
    "          1.15354022e-02,   3.44388521e-01,   1.35087469e-10,\n",
    "          1.06522873e-01,   9.97927645e-01,   6.38884095e-04,\n",
    "          7.66248178e-04,   1.00000000e+00,   6.80786687e-02,\n",
    "          2.02558106e-04,   2.09327121e-01,   3.78816999e-02,\n",
    "          6.67393835e-02,   1.51652013e-01],[  2.40091128e-01,   8.22608212e-01,   1.76171775e-02,\n",
    "          1.14641393e-02,   3.36865627e-01,   1.55087221e-10,\n",
    "          9.34424920e-02,   9.98822186e-01,   7.94379695e-04,\n",
    "          2.92804956e-04,   1.00000000e+00,   3.10136157e-02,\n",
    "          2.65540567e-04,   2.38821972e-01,   1.41763265e-02,\n",
    "          3.01164651e-02,   1.89523759e-01],[  2.80904333e-02,   9.44979372e-01,   1.20080454e-02,\n",
    "          1.21700717e-02,   3.57026689e-01,   1.40145534e-10,\n",
    "          1.14514573e-01,   9.98285609e-01,   4.95783072e-04,\n",
    "          8.27645169e-04,   1.00000000e+00,   4.31164902e-02,\n",
    "          3.69213619e-04,   2.11121570e-01,   2.68489173e-02,\n",
    "          4.10419569e-02,   5.82569091e-02],[  8.33343714e-02,   8.60734701e-01,   1.83451093e-02,\n",
    "          5.23094898e-03,   3.68032597e-01,   1.68173808e-10,\n",
    "          3.25095517e-02,   9.98353867e-01,   6.37757315e-04,\n",
    "          0.00000000e+00,   1.00000000e+00,   4.53857791e-03,\n",
    "          3.62471794e-05,   1.37701624e-01,   1.18400731e-03,\n",
    "          4.09383381e-03,   7.17884800e-02],[  5.47709289e-02,   8.81348807e-01,   5.88385376e-03,\n",
    "          1.28721395e-02,   3.96335201e-01,   1.38523693e-10,\n",
    "          4.05130298e-02,   9.98696827e-01,   6.32123417e-04,\n",
    "          1.13211803e-04,   1.00000000e+00,   5.97579425e-02,\n",
    "          7.43103861e-05,   8.56667172e-02,   2.48569499e-02,\n",
    "          5.74259020e-02,   1.24667819e-01],[  4.94077870e-01,   7.64775895e-01,   7.06962846e-03,\n",
    "          1.47619770e-02,   3.44007807e-01,   1.43563328e-10,\n",
    "          3.25059278e-01,   9.98473115e-01,   6.45644773e-04,\n",
    "          9.83816289e-04,   1.00000000e+00,   5.74886536e-02,\n",
    "          6.01400363e-04,   1.78777233e-01,   1.87790894e-02,\n",
    "          5.64352364e-02,   6.54046127e-02],[  3.69582396e-01,   8.39292565e-01,   1.48819165e-02,\n",
    "          1.44488567e-02,   3.66454893e-01,   1.48908608e-10,\n",
    "          1.14255608e-01,   9.99365483e-01,   3.48174930e-04,\n",
    "          6.99680411e-04,   1.00000000e+00,   6.05143722e-02,\n",
    "          2.28913481e-04,   1.01752807e-01,   2.37855420e-02,\n",
    "          5.84517012e-02,   1.16955169e-01],[  1.39088061e-01,   7.67499978e-01,   1.06032061e-02,\n",
    "          1.49374154e-02,   3.50821157e-01,   1.09669024e-10,\n",
    "          4.23270445e-01,   9.98564633e-01,   9.12691564e-05,\n",
    "          7.49947691e-04,   1.00000000e+00,   9.37972769e-02,\n",
    "          5.77128407e-04,   1.37554091e-01,   3.94378364e-02,\n",
    "          8.86418130e-02,   1.50516732e-01],[  7.60721292e-02,   7.83619080e-01,   1.36719864e-02,\n",
    "          1.29019149e-02,   3.53178277e-01,   1.72406894e-10,\n",
    "          9.03697886e-02,   9.98869165e-01,   5.45361379e-04,\n",
    "          2.85300789e-04,   1.00000000e+00,   9.15279879e-02,\n",
    "          4.73336495e-04,   1.34736912e-01,   2.82447863e-02,\n",
    "          9.42124948e-02,   2.47249157e-01],[  1.42779502e-01,   7.89367276e-01,   1.34501824e-02,\n",
    "          1.50271894e-02,   3.85675171e-01,   1.64320141e-10,\n",
    "          1.25856969e-01,   9.98419877e-01,   4.48458324e-04,\n",
    "          1.22035629e-03,   1.00000000e+00,   6.58093797e-02,\n",
    "          5.82637782e-04,   1.06381251e-01,   3.92415427e-02,\n",
    "          6.24773490e-02,   1.45810597e-01],[  2.45967016e-01,   8.89348403e-01,   2.09616044e-02,\n",
    "          1.47066633e-02,   3.31554197e-01,   1.37167111e-10,\n",
    "          1.63786201e-01,   9.98794729e-01,   4.43951205e-04,\n",
    "          7.84235886e-04,   1.00000000e+00,   7.03479576e-02,\n",
    "          3.14072418e-04,   1.02080670e-01,   4.53409075e-02,\n",
    "          6.59170152e-02,   1.91892701e-01],[  7.83399219e-02,   8.56397222e-01,   9.56752046e-03,\n",
    "          1.13252634e-02,   3.40749259e-01,   1.93979860e-10,\n",
    "          1.09785933e-01,   9.99304283e-01,   3.03103742e-04,\n",
    "          3.57084224e-04,   1.00000000e+00,   4.08472012e-02,\n",
    "          2.36650417e-04,   1.48282924e-02,   8.68713745e-03,\n",
    "          4.11605018e-02,   6.80158033e-02],[  5.90033023e-02,   8.28159001e-01,   2.18106028e-02,\n",
    "          1.37352971e-02,   3.51399490e-01,   1.43784512e-10,\n",
    "          2.03741993e-01,   9.98408824e-01,   3.48174930e-04,\n",
    "          1.01474938e-03,   1.00000000e+00,   3.17700454e-02,\n",
    "          4.08844027e-04,   1.67211864e-01,   1.88354083e-02,\n",
    "          2.99487021e-02,   7.77981650e-02],[  5.46228745e-02,   8.11367309e-01,   7.87936474e-03,\n",
    "          7.85719183e-03,   3.43817920e-01,   1.42962420e-10,\n",
    "          3.74203448e-02,   9.98320154e-01,   3.30146455e-04,\n",
    "          1.42987413e-04,   1.00000000e+00,   5.59757943e-02,\n",
    "          6.13020662e-05,   2.62111982e-01,   2.71273887e-02,\n",
    "          5.18725611e-02,   7.52165574e-02],[  2.65146394e-01,   6.25678065e-01,   1.29277915e-02,\n",
    "          1.41347884e-02,   3.58744112e-01,   2.55113319e-10,\n",
    "          2.77313662e-01,   9.99358561e-01,   7.51562066e-04,\n",
    "          1.57884555e-03,   1.00000000e+00,   1.05900151e-02,\n",
    "          4.66313978e-04,   2.35704311e-02,   5.34374981e-04,\n",
    "          9.87905725e-03,   1.89609830e-01],[  3.43229496e-03,   7.91864139e-01,   1.33463250e-02,\n",
    "          1.48939261e-02,   3.53144959e-01,   1.60602753e-10,\n",
    "          1.27693946e-01,   9.99187661e-01,   5.28459683e-04,\n",
    "          1.77106773e-04,   1.00000000e+00,   7.03479576e-02,\n",
    "          1.03321471e-03,   1.52390375e-01,   4.65501380e-02,\n",
    "          6.78250187e-02,   9.18383293e-02],[  1.00000000e+00,   9.62495784e-01,   9.89213015e-03,\n",
    "          1.50409449e-02,   3.53680609e-01,   1.26423566e-10,\n",
    "          1.05117121e-01,   9.98260696e-01,   5.10431208e-04,\n",
    "          5.58346609e-04,   1.00000000e+00,   8.16944024e-02,\n",
    "          9.04560640e-04,   1.80861511e-01,   2.61917086e-02,\n",
    "          8.21734025e-02,   1.59435070e-01],[  1.41523384e-01,   7.64762878e-01,   2.25988299e-02,\n",
    "          1.59262919e-02,   2.99569532e-01,   1.49648766e-10,\n",
    "          3.84039151e-01,   9.98756920e-01,   7.21139014e-04,\n",
    "          8.14779457e-04,   1.00000000e+00,   6.80786687e-02,\n",
    "          4.46828384e-04,   6.39376414e-02,   3.46956054e-02,\n",
    "          6.88816700e-02,   1.21050449e-01],[  2.12270696e-05,   9.16661335e-01,   3.56560501e-02,\n",
    "          1.12998041e-02,   3.08322157e-01,   1.34684125e-10,\n",
    "          1.88020285e-01,   9.98604533e-01,   4.12401373e-04,\n",
    "          6.22773316e-04,   1.00000000e+00,   3.72919818e-01,\n",
    "          2.59406566e-04,   1.05902056e-01,   1.86422805e-01,\n",
    "          3.54754270e-01,   1.51368247e-01],[  3.59450875e-01,   8.31472746e-01,   1.42701688e-02,\n",
    "          1.46446864e-02,   3.63778108e-01,   1.55104291e-10,\n",
    "          8.97216228e-02,   9.98994673e-01,   8.52972240e-04,\n",
    "          2.30943269e-04,   1.00000000e+00,   9.15279879e-02,\n",
    "          3.74119949e-04,   2.30105135e-01,   5.20646876e-02,\n",
    "          8.71518820e-02,   1.12465724e-01]])\n",
    "\n",
    "y = np.array([ 3,  3,  3, 15,  9,  7,  5,  7, 14,  9,  1,  7,  2, 13,  0,  5,  8,\n",
    "        1, 11, 11, 11, 11,  4, 11,  4,  4, 11, 11, 11,  0, 13, 15, 11, 11,\n",
    "        3, 11, 15, 13, 13,  1, 12, 12,  3, 11,  3,  3,  3,  3,  3,  3,  3,\n",
    "        3,  6, 15,  8,  9, 13,  5,  8, 15, 13, 11, 11, 11, 11, 12, 11, 11,\n",
    "       11, 11, 11, 11, 11, 11,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
    "        1,  1,  3,  9,  5,  5,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "        0,  0,  0, 13, 13])\n",
    "\n",
    "n = int(len(x) * 80 / 100)\n",
    "x_train, x_test = x[:n], x[n:]\n",
    "y_train, y_test = y[:n], y[n:]\n",
    "\n",
    "lr = 1/x_train.shape[1]        \n",
    "w = fit(x_train,np.array(y_train),lr)\n",
    "p_train = predict(x_train,np.array(w))\n",
    "\n",
    "p_test = predict(x_test, np.array(w))\n",
    "\n",
    "print(p_train, p_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hemos hecho anteriormente es clasificar los datos d prueba y de entrenamiento utilizando el coeficiente theta obtenido del ajuste con los datos de entrenamiento. Ahora vamos a evaluar la eficacia de nuestro análisis evaluando los porcentajes de entrenamiento y prueba de las medias harmónicas correspondientes. **Si la media harmónica de los datos de prueba es mayor que los datos de entrenamiento quiere decir que al menos hemos utilizado un buen conjunto de datos para reconocer la variable categórica y_i**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance general al entrenar los datos para reconocimiento de  Rock :  nan\n",
      "Performance general al entrenar los datos para reconocimiento de  Pop :  nan\n",
      "Performance general al entrenar los datos para reconocimiento de  Metal :  nan\n",
      "Performance general al entrenar los datos para reconocimiento de  samba :  nan\n",
      "Performance general al entrenar los datos para reconocimiento de  Rap :  nan\n",
      "Performance general al entrenar los datos para reconocimiento de  Electronic :  nan\n",
      "Performance general al entrenar los datos para reconocimiento de  experimental :  nan\n",
      "Performance general al entrenar los datos para reconocimiento de  Punk :  9.375\n",
      "Performance general al entrenar los datos para reconocimiento de  Latin :  nan\n",
      "Performance general al entrenar los datos para reconocimiento de  Folk :  nan\n",
      "Performance general al entrenar los datos para reconocimiento de  Jazz :  8.0\n",
      "Performance general al entrenar los datos para reconocimiento de  Blues :  nan\n",
      "Performance general al entrenar los datos para reconocimiento de  cumbia :  nan\n",
      "Performance general al entrenar los datos para reconocimiento de  flamenco :  nan\n",
      "Performance general al entrenar los datos para reconocimiento de  Native :  nan\n",
      "Performance general al evaluar el reconocimiento de  Rock :  nan\n",
      "Performance general al evaluar el reconocimiento de  Pop :  nan\n",
      "Performance general al evaluar el reconocimiento de  samba :  nan\n",
      "Performance general al evaluar el reconocimiento de  Electronic :  nan\n",
      "Performance general al evaluar el reconocimiento de  Folk :  nan\n",
      "Performance general al evaluar el reconocimiento de  cumbia :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "cf = confusion_matrix(y_train, p_train)\n",
    "\n",
    "TP = np.diag(cf)\n",
    "\n",
    "FP = cf.sum(axis=0) - TP\n",
    "\n",
    "FN = cf.sum(axis=1) - TP\n",
    "\n",
    "TN = cf.sum() - (FP + FN + TP) #verdadero negativo\n",
    "\n",
    "# reminiscencia (tamaño de verdaderos positivos)\n",
    "sensibilidad = TP/(TP+FN) * 100\n",
    "# tamaño de verdaderos negativos\n",
    "especificidad = TN/(TN+FP) * 100\n",
    "\n",
    "precision = TP/(TP+FP) * 100\n",
    "\n",
    "media_harmonica = 2 * ((precision * sensibilidad) / (precision + sensibilidad))\n",
    "\n",
    "for i,j in enumerate(np.unique(y_train)):\n",
    "    print(\"Performance general al entrenar los datos para reconocimiento de \", generos[j], ': ', media_harmonica[i])\n",
    "\n",
    "cf = confusion_matrix(y_test, p_test)\n",
    "\n",
    "TP = np.diag(cf)\n",
    "\n",
    "FP = cf.sum(axis=0) - TP\n",
    "\n",
    "FN = cf.sum(axis=1) - TP\n",
    "\n",
    "TN = cf.sum() - (FP + FN + TP) #verdadero negativo\n",
    "\n",
    "# reminiscencia (tamaño de verdaderos positivos)\n",
    "sensibilidad = TP/(TP+FN) * 100\n",
    "# tamaño de verdaderos negativos\n",
    "especificidad = TN/(TN+FP) * 100\n",
    "\n",
    "precision = TP/(TP+FP) * 100\n",
    "\n",
    "media_harmonica = 2 * ((precision * sensibilidad) / (precision + sensibilidad))\n",
    "\n",
    "for i,j in enumerate(np.unique(y_test)):\n",
    "    print(\"Performance general al evaluar el reconocimiento de \", generos[j], ': ', media_harmonica[i])    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué nos quieren decir estos resultados, por mas bajos que hayan sido?\n",
    "**Quieren decirnos que los resultados al evaluar el modelo serán buenos si los resultados de entrenamiento también los fueron, por lo que además los datos de entrenamiento deben proporcionar suficiente información para que la media harmónica también lo sea, lo cual implica mejorar siempre la calidad de la información brindada y (en algunos casos) elegir los rasgos mejor adecuados para resolver la tarea que queramos**.\n",
    "\n",
    "### Ejercicios\n",
    "\n",
    "#### 1. Un hospital quiere mejorar la respuesta médica a pacientes con enfermedades riesgosas y para eso quiere un agoritmo que permita clasificar a los pacientes de acuerdo al riesgo de la enfermedad que tienen, de forma tal que sea atendido primero el paciente con mayor probabilidad de morirse que los otros pacientes. Para aplicar en el algoritmo cuentan con una base de datos en csv que contiene información acerca de los pacientes. El propósito con este ejercicio es lograr que mediante regresión logística puedas clasificar a los pacientes de acuerdo al riesgo (riesgo leve, mediano y grave) obteniendo un promedio de media harmónica mayor al 50 por ciento para asegurarle al hospital que los enfermos con alta posibilidad de morirse serán atendidos primero y asi se salvarán más vidas.\n",
    "\n",
    "### Sugerencia\n",
    "    \n",
    "    * Utiliza numpy.mean para calcular el promedio de la media harmónica\n",
    "    * Para encontrar una buena solución al problema es necesario formular una buena hipótesis, para establecer una buena hipótesis es necesario conocer bien con qué valores contamos en nuestro conjunto de datos en x para así utilizar una matriz de datos que contenga los vectores de datos adecuados a nuestra hipótesis y a la relación que establecemos entre todas las partes para categorizar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataset = pd.read_csv('U.S._Chronic_Disease_Indicators__CDI_.csv')\n",
    "\n",
    "#Tu código aquí"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
